{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isotonic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATING: PREOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded original results from: /home/server/Projects/data/AKI/results/tabular_preop_test.pkl\n",
      "  -> Processing model: Logistic Regression\n",
      "     New F2-optimal threshold: 0.1430\n",
      "  -> Processing model: GBT\n",
      "     New F2-optimal threshold: 0.1183\n",
      "  -> Processing model: Random Forest\n",
      "     New F2-optimal threshold: 0.1331\n",
      "  -> Processing model: SVM (Linear)\n",
      "     New F2-optimal threshold: 0.1183\n",
      "  -> Processing model: MLP\n",
      "     New F2-optimal threshold: 0.1134\n",
      "  -> Processing model: KNN\n",
      "     New F2-optimal threshold: 0.1134\n",
      "  -> Processing model: ASA Rule\n",
      "     New F2-optimal threshold: 0.0297\n",
      "  -> Processing model: AutoGluon\n",
      "     New F2-optimal threshold: 0.1331\n",
      "\n",
      "Successfully saved calibrated results to: /home/server/Projects/data/AKI/results/tabular_preop_test_calibrated.pkl\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATION COMPLETE: PREOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATING: INTRAOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded original results from: /home/server/Projects/data/AKI/results/tabular_intraop_test.pkl\n",
      "  -> Processing model: Logistic Regression\n",
      "     New F2-optimal threshold: 0.0740\n",
      "  -> Processing model: GBT\n",
      "     New F2-optimal threshold: 0.0937\n",
      "  -> Processing model: Random Forest\n",
      "     New F2-optimal threshold: 0.0888\n",
      "  -> Processing model: SVM (Linear)\n",
      "     New F2-optimal threshold: 0.0789\n",
      "  -> Processing model: MLP\n",
      "     New F2-optimal threshold: 0.0888\n",
      "  -> Processing model: KNN\n",
      "     New F2-optimal threshold: 0.0740\n",
      "  -> Processing model: LSTM\n",
      "     New F2-optimal threshold: 0.0691\n",
      "  -> Processing model: AutoGluon\n",
      "     New F2-optimal threshold: 0.0888\n",
      "\n",
      "Successfully saved calibrated results to: /home/server/Projects/data/AKI/results/tabular_intraop_test_calibrated.pkl\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATION COMPLETE: INTRAOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATING: COMBINED ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded original results from: /home/server/Projects/data/AKI/results/tabular_combined_test.pkl\n",
      "  -> Processing model: Logistic Regression\n",
      "     New F2-optimal threshold: 0.1282\n",
      "  -> Processing model: GBT\n",
      "     New F2-optimal threshold: 0.1282\n",
      "  -> Processing model: Random Forest\n",
      "     New F2-optimal threshold: 0.1134\n",
      "  -> Processing model: SVM (Linear)\n",
      "     New F2-optimal threshold: 0.1134\n",
      "  -> Processing model: MLP\n",
      "     New F2-optimal threshold: 0.1233\n",
      "  -> Processing model: KNN\n",
      "     New F2-optimal threshold: 0.1036\n",
      "  -> Processing model: ASA Rule\n",
      "     New F2-optimal threshold: 0.0297\n",
      "  -> Processing model: Hybrid (MLP + LSTM)\n",
      "     New F2-optimal threshold: 0.0839\n",
      "  -> Processing model: AutoGluon\n",
      "     New F2-optimal threshold: 0.1183\n",
      "\n",
      "Successfully saved calibrated results to: /home/server/Projects/data/AKI/results/tabular_combined_test_calibrated.pkl\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ CALIBRATION COMPLETE: COMBINED ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.calibration import IsotonicRegression\n",
    "from sklearn.metrics import fbeta_score, roc_auc_score, average_precision_score, balanced_accuracy_score, confusion_matrix, precision_recall_curve, auc\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# =============================================================================\n",
    "# SCRIPT CONFIGURATION\n",
    "# =============================================================================\n",
    "# --- Analysis Mode ---\n",
    "# List of all possible data sources to calibrate\n",
    "ALL_DATA_SOURCES = [\"preop\", \"intraop\", \"combined\"]\n",
    "\n",
    "# --- Paths and Naming ---\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "# The script will load from e.g., 'tabular_preop_test.pkl'\n",
    "# and save to 'tabular_preop_test_calibrated.pkl'\n",
    "\n",
    "# --- Model Name Translations (ensure consistency) ---\n",
    "model_translate = {\n",
    "    'base': 'base', 'base_54k': 'base_54k',\n",
    "    'log_reg': 'Logistic Regression', 'xgb': 'GBT',\n",
    "    'svm': 'SVM (Linear)',\n",
    "    'mlp': 'MLP', 'rf': 'Random Forest',\n",
    "    'knn': 'KNN', 'asa_rule': 'ASA Rule', 'autogluon': 'AutoGluon',\n",
    "    'lstm': 'LSTM', 'hybrid': 'Hybrid (MLP + LSTM)'\n",
    "}\n",
    "\n",
    "# --- Base Model Mapping ---\n",
    "model_base_map = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'Hybrid (MLP + LSTM)': 'base_54k'\n",
    "}\n",
    "DEFAULT_BASE = 'base'\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def find_optimal_f2_threshold(y_true, y_prob):\n",
    "    \"\"\"\n",
    "    Finds the optimal probability threshold to maximize the F2-score.\n",
    "    \"\"\"\n",
    "    thresholds = np.linspace(0.01, 0.99, 200)\n",
    "    f2_scores = [fbeta_score(y_true, y_prob >= t, beta=2) for t in thresholds]\n",
    "    optimal_idx = np.argmax(f2_scores)\n",
    "    return thresholds[optimal_idx]\n",
    "\n",
    "def recompute_metrics_from_binary(y_true_folds, y_pred_binary_folds):\n",
    "    \"\"\"\n",
    "    Re-computes performance metrics from lists of true labels and binary predictions.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'balanced_accuracy': [], 'recall': [], 'precision': [],\n",
    "        'specificity': [], 'f1': []\n",
    "    }\n",
    "    \n",
    "    for y_true, y_pred in zip(y_true_folds, y_pred_binary_folds):\n",
    "        if len(np.unique(y_true)) < 2: # Handle folds with only one class\n",
    "            tn, fp, fn, tp = 0, 0, 0, 0\n",
    "            if np.unique(y_true)[0] == 0:\n",
    "                tn = len(y_true)\n",
    "                fp = np.sum(y_pred)\n",
    "            else:\n",
    "                tp = len(y_true)\n",
    "                fn = len(y_true) - np.sum(y_pred)\n",
    "        else:\n",
    "             tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        \n",
    "        metrics['recall'].append(tp / (tp + fn) if (tp + fn) > 0 else 0.0)\n",
    "        metrics['specificity'].append(tn / (tn + fp) if (tn + fp) > 0 else 0.0)\n",
    "        metrics['precision'].append(tp / (tp + fp) if (tp + fp) > 0 else 0.0)\n",
    "        metrics['f1'].append(fbeta_score(y_true, y_pred, beta=1))\n",
    "        metrics['balanced_accuracy'].append(balanced_accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    return metrics\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN CALIBRATION AND EVALUATION FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "def perform_calibration_and_evaluation(data_source):\n",
    "    \"\"\"\n",
    "    Orchestrates the entire calibration process for a given data source.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'~'*25} CALIBRATING: {data_source.upper()} {'~'*25}\\n\")\n",
    "    \n",
    "    # Define input and output file paths\n",
    "    input_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test.pkl\")\n",
    "    output_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test_calibrated.pkl\")\n",
    "\n",
    "    try:\n",
    "        df_original = pd.read_pickle(input_pkl)\n",
    "        # Apply model name translations\n",
    "        df_original['model_name'] = df_original['model_name'].map(model_translate)\n",
    "        df_original.dropna(subset=['model_name'], inplace=True)\n",
    "        print(f\"Successfully loaded original results from: {input_pkl}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Original results file not found at {input_pkl}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Prepare to store calibrated results\n",
    "    calibrated_results_list = []\n",
    "\n",
    "    # Separate base models (ground truth) from predictive models\n",
    "    df_base = df_original[df_original['model_name'].str.contains('base', na=False)].copy()\n",
    "    df_models = df_original[~df_original['model_name'].str.contains('base', na=False)].copy()\n",
    "\n",
    "    # --- Process each predictive model ---\n",
    "    for _, model_row in df_models.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        print(f\"  -> Processing model: {model_name}\")\n",
    "\n",
    "        # Determine which base model's ground truth to use\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        try:\n",
    "            y_true_folds = df_base[df_base['model_name'] == base_to_use]['y_pred_binary'].iloc[0]\n",
    "            y_prob_folds = model_row['y_prob']\n",
    "        except IndexError:\n",
    "            print(f\"     WARNING: Base model '{base_to_use}' not found for '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Concatenate fold data into single long vectors for calibration\n",
    "        y_true_flat = np.concatenate(y_true_folds)\n",
    "        y_prob_flat = np.concatenate(y_prob_folds)\n",
    "        \n",
    "        # Store original fold lengths to split data back later\n",
    "        fold_lengths = [len(fold) for fold in y_true_folds]\n",
    "        \n",
    "        # --- Calibrate Probabilities using Isotonic Regression with manual CV ---\n",
    "        calibrated_y_prob_flat = np.zeros_like(y_prob_flat)\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_idx, test_idx in kf.split(y_prob_flat):\n",
    "            isotonic_calibrator = IsotonicRegression(out_of_bounds='clip')\n",
    "            isotonic_calibrator.fit(y_prob_flat[train_idx], y_true_flat[train_idx])\n",
    "            calibrated_y_prob_flat[test_idx] = isotonic_calibrator.predict(y_prob_flat[test_idx])\n",
    "\n",
    "        # --- Find new threshold on calibrated probabilities ---\n",
    "        new_threshold = find_optimal_f2_threshold(y_true_flat, calibrated_y_prob_flat)\n",
    "        print(f\"     New F2-optimal threshold: {new_threshold:.4f}\")\n",
    "\n",
    "        # --- Generate new binary predictions ---\n",
    "        new_y_pred_binary_flat = (calibrated_y_prob_flat >= new_threshold).astype(int)\n",
    "\n",
    "        # --- Split flat arrays back into fold structure ---\n",
    "        cursor = 0\n",
    "        new_y_pred_binary_folds = []\n",
    "        calibrated_y_prob_folds = []\n",
    "        for length in fold_lengths:\n",
    "            new_y_pred_binary_folds.append(new_y_pred_binary_flat[cursor : cursor + length])\n",
    "            calibrated_y_prob_folds.append(calibrated_y_prob_flat[cursor : cursor + length])\n",
    "            cursor += length\n",
    "\n",
    "        # --- Re-compute threshold-dependent metrics ---\n",
    "        new_metrics = recompute_metrics_from_binary(y_true_folds, new_y_pred_binary_folds)\n",
    "        \n",
    "        # --- MODIFICATION: Calculate AUPRC per-fold from calibrated probabilities ---\n",
    "        auprc_scores = []\n",
    "        num_folds_to_process = min(len(y_true_folds), len(calibrated_y_prob_folds))\n",
    "        if num_folds_to_process < len(calibrated_y_prob_folds):\n",
    "            print(f\"     INFO [{model_name}]: Mismatched fold counts for AUPRC. Processing {num_folds_to_process} matching folds.\")\n",
    "        for i in range(num_folds_to_process):\n",
    "            if len(y_true_folds[i]) == len(calibrated_y_prob_folds[i]):\n",
    "                precision, recall, _ = precision_recall_curve(y_true_folds[i], calibrated_y_prob_folds[i])\n",
    "                auprc_scores.append(auc(recall, precision))\n",
    "        # --- END MODIFICATION ---\n",
    "\n",
    "        # Create a new row for the calibrated results DataFrame\n",
    "        new_row = model_row.copy()\n",
    "        \n",
    "        # Update the row with new data\n",
    "        new_row['y_prob'] = calibrated_y_prob_folds\n",
    "        new_row['y_pred_binary'] = new_y_pred_binary_folds\n",
    "        new_row['threshold'] = new_threshold\n",
    "        \n",
    "        for metric_name, values in new_metrics.items():\n",
    "            new_row[metric_name] = values\n",
    "        \n",
    "        # Add the newly calculated AUPRC scores\n",
    "        new_row['pr_auc'] = auprc_scores if auprc_scores else None\n",
    "            \n",
    "        calibrated_results_list.append(new_row)\n",
    "\n",
    "    # Combine calibrated models and original base models into one DataFrame\n",
    "    calibrated_df = pd.concat([pd.DataFrame(calibrated_results_list), df_base], ignore_index=True)\n",
    "\n",
    "    # Save the calibrated results to a new pickle file\n",
    "    with open(output_pkl, 'wb') as f:\n",
    "        pickle.dump(calibrated_df, f)\n",
    "    print(f\"\\nSuccessfully saved calibrated results to: {output_pkl}\")\n",
    "    print(f\"{'~'*25} CALIBRATION COMPLETE: {data_source.upper()} {'~'*25}\\n\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION BLOCK\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    for source in ALL_DATA_SOURCES:\n",
    "        perform_calibration_and_evaluation(source)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ RUNNING ANALYSIS FOR: PREOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded and processed results from: /home/server/Projects/data/AKI/results/tabular_preop_test.pkl\n",
      "Found models: ['Logistic Regression', 'GBT', 'Random Forest', 'SVM (Linear)', 'MLP', 'KNN', 'ASA Rule', 'AutoGluon']\n",
      "Saved ROC curve plot to: figures/curves/roc_curves_preop.png\n",
      "Saved Precision-Recall curve plot to: figures/curves/pr_curves_preop.png\n",
      "Saved calibration curve plot to: figures/curves/calibration_curves_preop.png\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE METRICS SUMMARY (PREOP)\n",
      "================================================================================\n",
      "Model                     Metric               Mean       95% CI Lower    95% CI Upper   \n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression      \n",
      "                          roc_auc              0.9122     0.9097          0.9148         \n",
      "                          balanced_accuracy    0.8410     0.8380          0.8439         \n",
      "                          recall               0.8043     0.7982          0.8105         \n",
      "                          precision            0.2363     0.2344          0.2382         \n",
      "                          specificity          0.8776     0.8764          0.8788         \n",
      "                          f1                   0.3652     0.3626          0.3679         \n",
      "--------------------------------------------------------------------------------\n",
      "GBT                      \n",
      "                          roc_auc              0.9260     0.9238          0.9283         \n",
      "                          balanced_accuracy    0.7992     0.7960          0.8024         \n",
      "                          recall               0.6265     0.6201          0.6329         \n",
      "                          precision            0.5123     0.5065          0.5181         \n",
      "                          specificity          0.9719     0.9712          0.9725         \n",
      "                          f1                   0.5635     0.5586          0.5684         \n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest            \n",
      "                          roc_auc              0.9259     0.9234          0.9283         \n",
      "                          balanced_accuracy    0.7943     0.7911          0.7975         \n",
      "                          recall               0.6167     0.6103          0.6231         \n",
      "                          precision            0.5085     0.5041          0.5130         \n",
      "                          specificity          0.9719     0.9715          0.9724         \n",
      "                          f1                   0.5573     0.5529          0.5617         \n",
      "--------------------------------------------------------------------------------\n",
      "SVM (Linear)             \n",
      "                          roc_auc              0.9130     0.9104          0.9155         \n",
      "                          balanced_accuracy    0.8404     0.8372          0.8436         \n",
      "                          recall               0.8020     0.7952          0.8087         \n",
      "                          precision            0.2375     0.2357          0.2393         \n",
      "                          specificity          0.8788     0.8777          0.8799         \n",
      "                          f1                   0.3664     0.3639          0.3690         \n",
      "--------------------------------------------------------------------------------\n",
      "MLP                      \n",
      "                          roc_auc              0.9189     0.9168          0.9210         \n",
      "                          balanced_accuracy    0.8445     0.8418          0.8471         \n",
      "                          recall               0.8135     0.8067          0.8202         \n",
      "                          precision            0.2354     0.2325          0.2383         \n",
      "                          specificity          0.8755     0.8729          0.8781         \n",
      "                          f1                   0.3651     0.3617          0.3684         \n",
      "--------------------------------------------------------------------------------\n",
      "KNN                      \n",
      "                          roc_auc              0.9091     0.9065          0.9117         \n",
      "                          balanced_accuracy    0.5630     0.5601          0.5660         \n",
      "                          recall               0.1264     0.1206          0.1322         \n",
      "                          precision            0.9489     0.9391          0.9587         \n",
      "                          specificity          0.9997     0.9996          0.9997         \n",
      "                          f1                   0.2228     0.2137          0.2320         \n",
      "--------------------------------------------------------------------------------\n",
      "ASA Rule                 \n",
      "                          roc_auc              0.7577     0.7546          0.7607         \n",
      "                          balanced_accuracy    0.5297     0.5276          0.5318         \n",
      "                          recall               0.0669     0.0627          0.0712         \n",
      "                          precision            0.2948     0.2798          0.3098         \n",
      "                          specificity          0.9925     0.9922          0.9927         \n",
      "                          f1                   0.1090     0.1025          0.1155         \n",
      "--------------------------------------------------------------------------------\n",
      "AutoGluon                \n",
      "                          roc_auc              0.9306     0.9281          0.9331         \n",
      "                          balanced_accuracy    0.8531     0.8497          0.8564         \n",
      "                          recall               0.8195     0.8108          0.8281         \n",
      "                          precision            0.2545     0.2498          0.2592         \n",
      "                          specificity          0.8867     0.8832          0.8901         \n",
      "                          f1                   0.3881     0.3831          0.3932         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPLETED ANALYSIS FOR: PREOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ RUNNING ANALYSIS FOR: INTRAOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded and processed results from: /home/server/Projects/data/AKI/results/tabular_intraop_test.pkl\n",
      "Found models: ['Logistic Regression', 'GBT', 'Random Forest', 'SVM (Linear)', 'MLP', 'KNN', 'LSTM', 'AutoGluon']\n",
      "Saved ROC curve plot to: figures/curves/roc_curves_intraop.png\n",
      "Saved Precision-Recall curve plot to: figures/curves/pr_curves_intraop.png\n",
      "Saved calibration curve plot to: figures/curves/calibration_curves_intraop.png\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE METRICS SUMMARY (INTRAOP)\n",
      "================================================================================\n",
      "Model                     Metric               Mean       95% CI Lower    95% CI Upper   \n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression      \n",
      "                          roc_auc              0.8073     0.8038          0.8108         \n",
      "                          balanced_accuracy    0.7385     0.7343          0.7426         \n",
      "                          recall               0.7080     0.6986          0.7175         \n",
      "                          precision            0.1260     0.1247          0.1274         \n",
      "                          specificity          0.7689     0.7661          0.7717         \n",
      "                          f1                   0.2140     0.2117          0.2162         \n",
      "--------------------------------------------------------------------------------\n",
      "GBT                      \n",
      "                          roc_auc              0.8509     0.8473          0.8545         \n",
      "                          balanced_accuracy    0.7502     0.7458          0.7547         \n",
      "                          recall               0.5917     0.5822          0.6013         \n",
      "                          precision            0.2340     0.2306          0.2375         \n",
      "                          specificity          0.9088     0.9070          0.9105         \n",
      "                          f1                   0.3353     0.3309          0.3397         \n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest            \n",
      "                          roc_auc              0.8438     0.8404          0.8473         \n",
      "                          balanced_accuracy    0.6133     0.6105          0.6162         \n",
      "                          recall               0.2443     0.2388          0.2499         \n",
      "                          precision            0.3951     0.3855          0.4046         \n",
      "                          specificity          0.9824     0.9818          0.9829         \n",
      "                          f1                   0.3018     0.2954          0.3082         \n",
      "--------------------------------------------------------------------------------\n",
      "SVM (Linear)             \n",
      "                          roc_auc              0.8236     0.8199          0.8273         \n",
      "                          balanced_accuracy    0.7521     0.7480          0.7561         \n",
      "                          recall               0.7103     0.7016          0.7190         \n",
      "                          precision            0.1395     0.1382          0.1409         \n",
      "                          specificity          0.7939     0.7924          0.7954         \n",
      "                          f1                   0.2333     0.2310          0.2355         \n",
      "--------------------------------------------------------------------------------\n",
      "MLP                      \n",
      "                          roc_auc              0.8257     0.8227          0.8288         \n",
      "                          balanced_accuracy    0.7540     0.7497          0.7582         \n",
      "                          recall               0.7078     0.6977          0.7178         \n",
      "                          precision            0.1430     0.1411          0.1448         \n",
      "                          specificity          0.8002     0.7967          0.8037         \n",
      "                          f1                   0.2378     0.2350          0.2406         \n",
      "--------------------------------------------------------------------------------\n",
      "KNN                      \n",
      "                          roc_auc              0.7659     0.7632          0.7686         \n",
      "                          balanced_accuracy    0.5000     N/A             N/A            \n",
      "                          recall               0.0000     N/A             N/A            \n",
      "                          precision            0.0000     N/A             N/A            \n",
      "                          specificity          1.0000     N/A             N/A            \n",
      "                          f1                   0.0000     N/A             N/A            \n",
      "--------------------------------------------------------------------------------\n",
      "LSTM                     \n",
      "                          roc_auc              0.7387     0.7325          0.7449         \n",
      "                          balanced_accuracy    0.6725     0.6673          0.6778         \n",
      "                          recall               0.6276     0.6115          0.6436         \n",
      "                          precision            0.1246     0.1217          0.1275         \n",
      "                          specificity          0.7175     0.7062          0.7288         \n",
      "                          f1                   0.2077     0.2038          0.2116         \n",
      "--------------------------------------------------------------------------------\n",
      "AutoGluon                \n",
      "                          roc_auc              0.8581     0.8539          0.8623         \n",
      "                          balanced_accuracy    0.7813     0.7754          0.7871         \n",
      "                          recall               0.7295     0.7149          0.7442         \n",
      "                          precision            0.1708     0.1678          0.1738         \n",
      "                          specificity          0.8330     0.8279          0.8380         \n",
      "                          f1                   0.2766     0.2725          0.2808         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPLETED ANALYSIS FOR: INTRAOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ RUNNING ANALYSIS FOR: COMBINED ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Successfully loaded and processed results from: /home/server/Projects/data/AKI/results/tabular_combined_test.pkl\n",
      "Found models: ['Logistic Regression', 'GBT', 'Random Forest', 'SVM (Linear)', 'MLP', 'KNN', 'ASA Rule', 'Hybrid (MLP + LSTM)', 'AutoGluon']\n",
      "Saved ROC curve plot to: figures/curves/roc_curves_combined.png\n",
      "Saved Precision-Recall curve plot to: figures/curves/pr_curves_combined.png\n",
      "Saved calibration curve plot to: figures/curves/calibration_curves_combined.png\n",
      "\n",
      "================================================================================\n",
      "PERFORMANCE METRICS SUMMARY (COMBINED)\n",
      "================================================================================\n",
      "Model                     Metric               Mean       95% CI Lower    95% CI Upper   \n",
      "--------------------------------------------------------------------------------\n",
      "Logistic Regression      \n",
      "                          roc_auc              0.9175     0.9151          0.9199         \n",
      "                          balanced_accuracy    0.8460     0.8429          0.8491         \n",
      "                          recall               0.8044     0.7980          0.8108         \n",
      "                          precision            0.2522     0.2499          0.2544         \n",
      "                          specificity          0.8877     0.8864          0.8889         \n",
      "                          f1                   0.3839     0.3809          0.3870         \n",
      "--------------------------------------------------------------------------------\n",
      "GBT                      \n",
      "                          roc_auc              0.9300     0.9281          0.9320         \n",
      "                          balanced_accuracy    0.7600     0.7567          0.7633         \n",
      "                          recall               0.5309     0.5241          0.5376         \n",
      "                          precision            0.6958     0.6895          0.7021         \n",
      "                          specificity          0.9891     0.9887          0.9894         \n",
      "                          f1                   0.6020     0.5971          0.6070         \n",
      "--------------------------------------------------------------------------------\n",
      "Random Forest            \n",
      "                          roc_auc              0.9254     0.9228          0.9279         \n",
      "                          balanced_accuracy    0.7471     0.7442          0.7500         \n",
      "                          recall               0.5059     0.4998          0.5120         \n",
      "                          precision            0.6706     0.6639          0.6772         \n",
      "                          specificity          0.9883     0.9879          0.9887         \n",
      "                          f1                   0.5765     0.5724          0.5806         \n",
      "--------------------------------------------------------------------------------\n",
      "SVM (Linear)             \n",
      "                          roc_auc              0.9181     0.9158          0.9204         \n",
      "                          balanced_accuracy    0.8475     0.8447          0.8503         \n",
      "                          recall               0.8205     0.8151          0.8259         \n",
      "                          precision            0.2354     0.2335          0.2373         \n",
      "                          specificity          0.8746     0.8736          0.8756         \n",
      "                          f1                   0.3659     0.3632          0.3686         \n",
      "--------------------------------------------------------------------------------\n",
      "MLP                      \n",
      "                          roc_auc              0.9193     0.9171          0.9214         \n",
      "                          balanced_accuracy    0.8456     0.8427          0.8486         \n",
      "                          recall               0.8140     0.8076          0.8205         \n",
      "                          precision            0.2381     0.2353          0.2408         \n",
      "                          specificity          0.8773     0.8751          0.8794         \n",
      "                          f1                   0.3683     0.3649          0.3717         \n",
      "--------------------------------------------------------------------------------\n",
      "KNN                      \n",
      "                          roc_auc              0.8733     0.8706          0.8761         \n",
      "                          balanced_accuracy    0.5000     N/A             N/A            \n",
      "                          recall               0.0000     N/A             N/A            \n",
      "                          precision            0.0000     N/A             N/A            \n",
      "                          specificity          1.0000     N/A             N/A            \n",
      "                          f1                   0.0000     N/A             N/A            \n",
      "--------------------------------------------------------------------------------\n",
      "ASA Rule                 \n",
      "                          roc_auc              0.7577     0.7546          0.7607         \n",
      "                          balanced_accuracy    0.5297     0.5276          0.5318         \n",
      "                          recall               0.0669     0.0627          0.0712         \n",
      "                          precision            0.2948     0.2798          0.3098         \n",
      "                          specificity          0.9925     0.9922          0.9927         \n",
      "                          f1                   0.1090     0.1025          0.1155         \n",
      "--------------------------------------------------------------------------------\n",
      "Hybrid (MLP + LSTM)      \n",
      "                          roc_auc              0.8253     0.8001          0.8505         \n",
      "                          balanced_accuracy    0.7475     0.7147          0.7802         \n",
      "                          recall               0.7078     0.6153          0.8003         \n",
      "                          precision            0.1854     0.1704          0.2004         \n",
      "                          specificity          0.7871     0.7555          0.8187         \n",
      "                          f1                   0.2727     0.2498          0.2956         \n",
      "--------------------------------------------------------------------------------\n",
      "AutoGluon                \n",
      "                          roc_auc              0.9325     0.9303          0.9347         \n",
      "                          balanced_accuracy    0.8535     0.8506          0.8565         \n",
      "                          recall               0.8035     0.7954          0.8116         \n",
      "                          precision            0.2836     0.2747          0.2925         \n",
      "                          specificity          0.9036     0.8987          0.9084         \n",
      "                          f1                   0.4185     0.4094          0.4277         \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPLETED ANALYSIS FOR: COMBINED ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# SCRIPT CONFIGURATION\n",
    "# =============================================================================\n",
    "# --- Analysis Mode ---\n",
    "# Set to True to run for all sources in ALL_DATA_SOURCES.\n",
    "# Set to False to run only for the single source specified in DATA_SOURCE.\n",
    "ANALYZE_ALL_SOURCES = True\n",
    "\n",
    "# --- NEW: Plotting Options ---\n",
    "# Set to True to display shaded confidence intervals on ROC and PR curves.\n",
    "PLOT_CONFIDENCE_INTERVALS = True\n",
    "\n",
    "# --- Select which dataset's results you want to analyze (if ANALYZE_ALL_SOURCES is False) ---\n",
    "DATA_SOURCE = \"intraop\"\n",
    "\n",
    "# --- List of all possible data sources (used when ANALYZE_ALL_SOURCES is True) ---\n",
    "ALL_DATA_SOURCES = [\"preop\", \"intraop\", \"combined\"]\n",
    "\n",
    "# --- Paths and Naming ---\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "FIGURES_DIR = 'figures/curves'  # Define the folder to save plots\n",
    "\n",
    "# Note: The full path will be constructed dynamically in the analysis function.\n",
    "\n",
    "# --- Model Name Translations for Plots ---\n",
    "model_translate = {\n",
    "    'base': 'base', 'base_54k': 'base_54k', # Add any new base models here\n",
    "    'log_reg': 'Logistic Regression', 'xgb': 'GBT',\n",
    "    'svm': 'SVM (Linear)',  # MODIFIED: Changed 'svm_linear' to 'svm' to match first script\n",
    "    'mlp': 'MLP', 'rf': 'Random Forest',\n",
    "    'knn': 'KNN', 'asa_rule': 'ASA Rule', 'autogluon': 'AutoGluon',\n",
    "    'lstm': 'LSTM', 'hybrid': 'Hybrid (MLP + LSTM)'\n",
    "}\n",
    "\n",
    "# Define which ground-truth 'base' model to use for specific predictive models.\n",
    "# This allows comparing models trained on different underlying datasets.\n",
    "# Models not listed here will use the DEFAULT_BASE.\n",
    "model_base_map = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'Hybrid (MLP + LSTM)': 'base_54k'\n",
    "}\n",
    "DEFAULT_BASE = 'base'\n",
    "\n",
    "\n",
    "# --- Consistent Color Mapping for Models ---\n",
    "model_colors = {\n",
    "    'Logistic Regression': 'green',\n",
    "    'GBT': 'red',\n",
    "    'SVM (Linear)': 'purple', # This entry is already correct\n",
    "    'MLP': 'brown',\n",
    "    'Random Forest': 'crimson',\n",
    "    'KNN': 'gray',\n",
    "    'ASA Rule': 'orange',\n",
    "    'AutoGluon': 'blue',\n",
    "    'LSTM': 'darkorange',\n",
    "    'Hybrid (MLP + LSTM)': 'teal'\n",
    "}\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# PLOTTING FUNCTIONS (ADAPTED FOR NEW .pkl FORMAT)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_roc_curves(df, data_source_name, save_dir):\n",
    "    \"\"\"Plots the mean ROC curve for each model, optionally with a shaded confidence interval.\"\"\"\n",
    "    plt.figure(figsize=(10, 8), dpi=300)\n",
    "    \n",
    "    # Load all available 'base' models' ground-truth data\n",
    "    base_names = [name for name in df['model_name'].unique() if 'base' in name]\n",
    "    if not base_names:\n",
    "        print(\"ERROR: No 'base' model with true labels found. Cannot plot curves.\")\n",
    "        return\n",
    "        \n",
    "    base_models_data = {\n",
    "        name: df[df['model_name'] == name]['y_pred_binary'].values[0]\n",
    "        for name in base_names\n",
    "    }\n",
    "    \n",
    "    df_to_plot = df[~df['model_name'].str.contains('base')]\n",
    "    \n",
    "    # Pre-calculate AUCs to sort the legend\n",
    "    model_performance = []\n",
    "    for index, model_row in df_to_plot.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        \n",
    "        # Determine which base model's ground truth to use\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        if base_to_use not in base_models_data:\n",
    "            print(f\"WARNING [ROC]: Base model '{base_to_use}' for model '{model_name}' not found. Skipping.\")\n",
    "            continue\n",
    "        y_true_runs = base_models_data[base_to_use]\n",
    "\n",
    "        aucs = []\n",
    "        for i in range(len(model_row['y_prob'])):\n",
    "            if i >= len(y_true_runs) or len(y_true_runs[i]) != len(model_row['y_prob'][i]):\n",
    "                print(f\"WARNING [ROC]: Skipping fold {i} for model '{model_name}'. Inconsistent sample numbers.\")\n",
    "                continue\n",
    "            fpr, tpr, _ = roc_curve(y_true_runs[i], model_row['y_prob'][i])\n",
    "            aucs.append(auc(fpr, tpr))\n",
    "\n",
    "        if not aucs:\n",
    "            print(f\"WARNING [ROC]: Could not calculate AUC for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        model_performance.append((model_name, np.mean(aucs), model_row))\n",
    "    \n",
    "    model_performance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for model_name, mean_auc, model_row in model_performance:\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        y_true_runs = base_models_data[base_to_use]\n",
    "        y_prob_runs = model_row['y_prob']\n",
    "        \n",
    "        mean_fpr = np.linspace(0, 1, 100)\n",
    "        tprs = []\n",
    "        for i in range(len(y_prob_runs)):\n",
    "            if i >= len(y_true_runs) or len(y_true_runs[i]) != len(y_prob_runs[i]):\n",
    "                continue\n",
    "            fpr, tpr, _ = roc_curve(y_true_runs[i], y_prob_runs[i])\n",
    "            interp_tpr = np.interp(mean_fpr, fpr, tpr)\n",
    "            interp_tpr[0] = 0.0\n",
    "            tprs.append(interp_tpr)\n",
    "        \n",
    "        if not tprs: continue\n",
    "            \n",
    "        mean_tpr = np.mean(tprs, axis=0)\n",
    "        mean_tpr[-1] = 1.0\n",
    "        color = model_colors.get(model_name, None)\n",
    "        \n",
    "        # --- MODIFIED: Conditionally plot confidence interval ---\n",
    "        if PLOT_CONFIDENCE_INTERVALS:\n",
    "            # The shaded region represents +/- 1 standard deviation from the mean TPR.\n",
    "            std_tpr = np.std(tprs, axis=0)\n",
    "            tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "            tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "            plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color=color, alpha=0.2)\n",
    "        # --- END MODIFIED ---\n",
    "\n",
    "        valid_aucs = [auc(roc_curve(y_true_runs[i], y_prob_runs[i])[0], roc_curve(y_true_runs[i], y_prob_runs[i])[1]) for i in range(len(y_prob_runs)) if i < len(y_true_runs) and len(y_true_runs[i]) == len(y_prob_runs[i])]\n",
    "        std_auc = np.std(valid_aucs)\n",
    "        \n",
    "        plt.plot(mean_fpr, mean_tpr, color=color, label=f'{model_name} (AUC = {mean_auc:.2f} \\u00B1 {std_auc:.2f})', lw=2)\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Chance')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Mean ROC Curves on {data_source_name.upper()} Data')\n",
    "    plt.legend(loc='lower right', fontsize='large')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'roc_curves_{data_source_name}.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"Saved ROC curve plot to: {save_path}\")\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "def plot_pr_curves(df, data_source_name, save_dir):\n",
    "    \"\"\"Plots the mean Precision-Recall curve for each model, optionally with a shaded confidence interval.\"\"\"\n",
    "    plt.figure(figsize=(10, 8), dpi=300)\n",
    "    \n",
    "    base_names = [name for name in df['model_name'].unique() if 'base' in name]\n",
    "    if not base_names:\n",
    "        print(\"ERROR: No 'base' model with true labels found. Cannot plot curves.\")\n",
    "        return\n",
    "        \n",
    "    base_models_data = {\n",
    "        name: df[df['model_name'] == name]['y_pred_binary'].values[0]\n",
    "        for name in base_names\n",
    "    }\n",
    "    \n",
    "    df_to_plot = df[~df['model_name'].str.contains('base')]\n",
    "    \n",
    "    model_performance = []\n",
    "    for index, model_row in df_to_plot.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        if base_to_use not in base_models_data:\n",
    "            print(f\"WARNING [PR]: Base model '{base_to_use}' for model '{model_name}' not found. Skipping.\")\n",
    "            continue\n",
    "        y_true_runs = base_models_data[base_to_use]\n",
    "        \n",
    "        pr_aucs = []\n",
    "        for i in range(len(model_row['y_prob'])):\n",
    "            if i >= len(y_true_runs) or len(y_true_runs[i]) != len(model_row['y_prob'][i]):\n",
    "                print(f\"WARNING [PR]: Skipping fold {i} for model '{model_name}'. Inconsistent sample numbers.\")\n",
    "                continue\n",
    "            precision, recall, _ = precision_recall_curve(y_true_runs[i], model_row['y_prob'][i])\n",
    "            pr_aucs.append(auc(recall, precision))\n",
    "\n",
    "        if not pr_aucs:\n",
    "            print(f\"WARNING [PR]: Could not calculate AUC for model '{model_name}'. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        model_performance.append((model_row['model_name'], np.mean(pr_aucs), model_row))\n",
    "\n",
    "    model_performance.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    for model_name, mean_pr_auc, model_row in model_performance:\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        y_true_runs = base_models_data[base_to_use]\n",
    "        y_prob_runs = model_row['y_prob']\n",
    "        \n",
    "        mean_recall = np.linspace(0, 1, 100)\n",
    "        precisions = []\n",
    "        for i in range(len(y_prob_runs)):\n",
    "            if i >= len(y_true_runs) or len(y_true_runs[i]) != len(y_prob_runs[i]):\n",
    "                continue\n",
    "            precision, recall, _ = precision_recall_curve(y_true_runs[i], y_prob_runs[i])\n",
    "            # Interpolate precision values for a common recall axis\n",
    "            interp_prec = np.interp(mean_recall, recall[::-1], precision[::-1])\n",
    "            precisions.append(interp_prec)\n",
    "\n",
    "        if not precisions: continue\n",
    "\n",
    "        mean_prec = np.mean(precisions, axis=0)\n",
    "        color = model_colors.get(model_name, None)\n",
    "        \n",
    "        # --- MODIFIED: Conditionally plot confidence interval ---\n",
    "        if PLOT_CONFIDENCE_INTERVALS:\n",
    "            # The shaded region represents +/- 1 standard deviation from the mean precision.\n",
    "            std_prec = np.std(precisions, axis=0)\n",
    "            prec_upper = np.minimum(mean_prec + std_prec, 1)\n",
    "            prec_lower = np.maximum(mean_prec - std_prec, 0)\n",
    "            plt.fill_between(mean_recall, prec_lower, prec_upper, color=color, alpha=0.2)\n",
    "        # --- END MODIFIED ---\n",
    "\n",
    "        valid_pr_aucs = [auc(precision_recall_curve(y_true_runs[i], y_prob_runs[i])[1], precision_recall_curve(y_true_runs[i], y_prob_runs[i])[0]) for i in range(len(y_prob_runs)) if i < len(y_true_runs) and len(y_true_runs[i]) == len(y_prob_runs[i])]\n",
    "        std_pr_auc = np.std(valid_pr_aucs)\n",
    "\n",
    "        plt.plot(mean_recall, mean_prec, color=color, label=f'{model_name} (AUC = {mean_pr_auc:.2f} \\u00B1 {std_pr_auc:.2f})', lw=2)\n",
    "\n",
    "    # Use the default base for the 'no skill' line as a general reference\n",
    "    y_true_default_runs = base_models_data[DEFAULT_BASE]\n",
    "    y_true_default_flat = np.concatenate(y_true_default_runs)\n",
    "    no_skill = len(y_true_default_flat[y_true_default_flat==1]) / len(y_true_default_flat)\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='gray', label='No Skill')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Mean Precision-Recall Curves on {data_source_name.upper()} Data')\n",
    "    plt.legend(loc='upper right', fontsize='large')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'pr_curves_{data_source_name}.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"Saved Precision-Recall curve plot to: {save_path}\")\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "def plot_calibration_curves(df, data_source_name, save_dir):\n",
    "    \"\"\"Plots calibration curves by pooling all predictions and saves the figure.\"\"\"\n",
    "    plt.figure(figsize=(10, 8), dpi=300)\n",
    "    \n",
    "    base_names = [name for name in df['model_name'].unique() if 'base' in name]\n",
    "    if not base_names:\n",
    "        print(\"ERROR: No 'base' model with true labels found. Cannot plot curves.\")\n",
    "        return\n",
    "        \n",
    "    base_models_data = {\n",
    "        name: df[df['model_name'] == name]['y_pred_binary'].values[0]\n",
    "        for name in base_names\n",
    "    }\n",
    "\n",
    "    df_to_plot = df[~df['model_name'].str.contains('base')]\n",
    "\n",
    "    for index, model_row in df_to_plot.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        if base_to_use not in base_models_data:\n",
    "            print(f\"WARNING [Calibration]: Base model '{base_to_use}' for model '{model_name}' not found. Skipping.\")\n",
    "            continue\n",
    "            \n",
    "        y_true_runs = base_models_data[base_to_use]\n",
    "        y_prob_runs = model_row['y_prob']\n",
    "        \n",
    "        # Check for total length consistency before concatenating\n",
    "        len_y_true = sum(len(arr) for arr in y_true_runs)\n",
    "        len_y_prob = sum(len(arr) for arr in y_prob_runs)\n",
    "\n",
    "        if len_y_true != len_y_prob:\n",
    "            print(f\"WARNING [Calibration]: Skipping model '{model_name}'. Pooled predictions have mismatched samples.\")\n",
    "            continue\n",
    "            \n",
    "        y_true_all = np.concatenate(y_true_runs)\n",
    "        y_prob_all = np.concatenate(y_prob_runs)\n",
    "\n",
    "        prob_true, prob_pred = calibration_curve(y_true_all, y_prob_all, n_bins=15, strategy='uniform')\n",
    "        plt.plot(prob_pred, prob_true, marker='o', linestyle='-', color=model_colors.get(model_name, None), label=f'{model_name}')\n",
    "\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "    plt.xlabel('Mean Predicted Probability')\n",
    "    plt.ylabel('Fraction of Positives')\n",
    "    plt.title(f'Calibration Curves on {data_source_name.upper()} Data')\n",
    "    plt.legend(loc='upper left', fontsize='large')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the figure\n",
    "    save_path = os.path.join(save_dir, f'calibration_curves_{data_source_name}.png')\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    print(f\"Saved calibration curve plot to: {save_path}\")\n",
    "    plt.close() # Close the plot to free memory\n",
    "\n",
    "# =============================================================================\n",
    "# METRICS TABLE FUNCTION\n",
    "# =============================================================================\n",
    "def print_metrics_table(df, data_source_name):\n",
    "    \"\"\"Prints a formatted table of performance metrics with 95% CIs.\"\"\"\n",
    "    df_to_print = df[~df['model_name'].str.contains('base')].copy()\n",
    "    \n",
    "    metrics_to_print = ['roc_auc', 'balanced_accuracy', 'recall', 'precision', 'specificity', 'f1']\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"PERFORMANCE METRICS SUMMARY ({data_source_name.upper()})\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<25} {'Metric':<20} {'Mean':<10} {'95% CI Lower':<15} {'95% CI Upper':<15}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "    for index, model_row in df_to_print.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        print(f\"{model_name:<25}\")\n",
    "        for metric in metrics_to_print:\n",
    "            if metric not in model_row or model_row[metric] is None or len(np.atleast_1d(model_row[metric])) == 0:\n",
    "                print(f\"{'':<25} {metric:<20} {'N/A':<10} {'N/A':<15} {'N/A':<15}\")\n",
    "                continue\n",
    "\n",
    "            arr = model_row[metric]\n",
    "            \n",
    "            if np.isscalar(arr) or len(arr) == 1:\n",
    "                mean = np.mean(arr)\n",
    "                ci_lower, ci_upper = \"N/A\", \"N/A\"\n",
    "            else:\n",
    "                mean = np.mean(arr)\n",
    "                sem = stats.sem(arr)\n",
    "                n = len(arr)\n",
    "\n",
    "                if sem > 0 and n > 1:\n",
    "                    ci = stats.t.interval(0.95, df=n-1, loc=mean, scale=sem)\n",
    "                    ci_lower, ci_upper = f\"{ci[0]:.4f}\", f\"{ci[1]:.4f}\"\n",
    "                else:\n",
    "                    ci_lower, ci_upper = \"N/A\", \"N/A\"\n",
    "            \n",
    "            print(f\"{'':<25} {metric:<20} {mean:<10.4f} {ci_lower:<15} {ci_upper:<15}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN ANALYSIS EXECUTION\n",
    "# =============================================================================\n",
    "def run_full_analysis(data_source):\n",
    "    \"\"\"\n",
    "    Loads data for a given source and runs all plotting and metric functions.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'~'*25} RUNNING ANALYSIS FOR: {data_source.upper()} {'~'*25}\\n\")\n",
    "    \n",
    "    # Create the figures directory if it doesn't exist\n",
    "    os.makedirs(FIGURES_DIR, exist_ok=True)\n",
    "    \n",
    "    output_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test.pkl\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_pickle(output_pkl)\n",
    "        df['model_name'] = df['model_name'].map(model_translate)\n",
    "        df.dropna(subset=['model_name'], inplace=True)\n",
    "        print(f\"Successfully loaded and processed results from: {output_pkl}\")\n",
    "        found_models = df[~df['model_name'].str.contains('base')]['model_name'].unique().tolist()\n",
    "        print(f\"Found models: {found_models}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Results file not found at {output_pkl}. Skipping this data source.\")\n",
    "        return\n",
    "\n",
    "    # Pass the save directory to the plotting functions\n",
    "    plot_roc_curves(df, data_source, FIGURES_DIR)\n",
    "    plot_pr_curves(df, data_source, FIGURES_DIR)\n",
    "    plot_calibration_curves(df, data_source, FIGURES_DIR)\n",
    "    \n",
    "    print_metrics_table(df, data_source)\n",
    "    print(f\"\\n{'~'*25} COMPLETED ANALYSIS FOR: {data_source.upper()} {'~'*25}\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if ANALYZE_ALL_SOURCES:\n",
    "        for source in ALL_DATA_SOURCES:\n",
    "            run_full_analysis(source)\n",
    "    else:\n",
    "        run_full_analysis(DATA_SOURCE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded data for: PREOP\n",
      "Successfully loaded data for: INTRAOP\n",
      "Successfully loaded data for: COMBINED\n",
      "\n",
      "Successfully saved Markdown table to: performance_table.md\n",
      "\n",
      "--- Generated Markdown Table ---\n",
      "\n",
      "| Model | AUROC | AUPRC | Sensitivity | Specificity | Precision | F-score | Accuracy |\n",
      "|---|---|---|---|---|---|---|---|\n",
      "| **Preop Data** | | | | | | | |\n",
      "| ASA Rule | 0.758 | 0.192 | 0.067 | 0.992 | 0.295 | 0.109 | 0.530 |\n",
      "|  | (0.755, 0.761) | (0.185, 0.199) | (0.063, 0.071) | (0.992, 0.993) | (0.280, 0.310) | (0.103, 0.116) | (0.528, 0.532) |\n",
      "| AutoGluon | 0.931 | 0.625 | 0.819 | 0.887 | 0.254 | 0.388 | 0.853 |\n",
      "|  | (0.928, 0.933) | (0.618, 0.631) | (0.811, 0.828) | (0.883, 0.890) | (0.250, 0.259) | (0.383, 0.393) | (0.850, 0.856) |\n",
      "| GBT | 0.926 | 0.614 | 0.626 | 0.972 | 0.512 | 0.564 | 0.799 |\n",
      "|  | (0.924, 0.928) | (0.609, 0.620) | (0.620, 0.633) | (0.971, 0.973) | (0.506, 0.518) | (0.559, 0.568) | (0.796, 0.802) |\n",
      "| KNN | 0.909 | 0.542 | 0.126 | 1.000 | 0.949 | 0.223 | 0.563 |\n",
      "|  | (0.907, 0.912) | (0.535, 0.550) | (0.121, 0.132) | (1.000, 1.000) | (0.939, 0.959) | (0.214, 0.232) | (0.560, 0.566) |\n",
      "| LR | 0.912 | 0.532 | 0.804 | 0.878 | 0.236 | 0.365 | 0.841 |\n",
      "|  | (0.910, 0.915) | (0.525, 0.539) | (0.798, 0.810) | (0.876, 0.879) | (0.234, 0.238) | (0.363, 0.368) | (0.838, 0.844) |\n",
      "| MLP | 0.919 | 0.588 | 0.813 | 0.875 | 0.235 | 0.365 | 0.844 |\n",
      "|  | (0.917, 0.921) | (0.581, 0.594) | (0.807, 0.820) | (0.873, 0.878) | (0.232, 0.238) | (0.362, 0.368) | (0.842, 0.847) |\n",
      "| RF | 0.926 | 0.584 | 0.617 | 0.972 | 0.509 | 0.557 | 0.794 |\n",
      "|  | (0.923, 0.928) | (0.578, 0.591) | (0.610, 0.623) | (0.971, 0.972) | (0.504, 0.513) | (0.553, 0.562) | (0.791, 0.797) |\n",
      "| SVM | 0.913 | 0.531 | 0.802 | 0.879 | 0.237 | 0.366 | 0.840 |\n",
      "|  | (0.910, 0.915) | (0.524, 0.538) | (0.795, 0.809) | (0.878, 0.880) | (0.236, 0.239) | (0.364, 0.369) | (0.837, 0.844) |\n",
      "| **Intraop Data** | | | | | | | |\n",
      "| AutoGluon | 0.858 | 0.342 | 0.730 | 0.833 | 0.171 | 0.277 | 0.781 |\n",
      "|  | (0.854, 0.862) | (0.334, 0.351) | (0.715, 0.744) | (0.828, 0.838) | (0.168, 0.174) | (0.273, 0.281) | (0.775, 0.787) |\n",
      "| GBT | 0.851 | 0.337 | 0.592 | 0.909 | 0.234 | 0.335 | 0.750 |\n",
      "|  | (0.847, 0.854) | (0.331, 0.343) | (0.582, 0.601) | (0.907, 0.911) | (0.231, 0.237) | (0.331, 0.340) | (0.746, 0.755) |\n",
      "| KNN | 0.766 | 0.160 | 0.000 | 1.000 | 0.000 | 0.000 | 0.500 |\n",
      "|  | (0.763, 0.769) | (0.156, 0.164) | N/A | N/A | N/A | N/A | N/A |\n",
      "| LR | 0.807 | 0.225 | 0.708 | 0.769 | 0.126 | 0.214 | 0.738 |\n",
      "|  | (0.804, 0.811) | (0.220, 0.231) | (0.699, 0.717) | (0.766, 0.772) | (0.125, 0.127) | (0.212, 0.216) | (0.734, 0.743) |\n",
      "| LSTM | 0.739 | 0.210 | 0.628 | 0.717 | 0.125 | 0.208 | 0.673 |\n",
      "|  | (0.732, 0.745) | (0.203, 0.217) | (0.612, 0.644) | (0.706, 0.729) | (0.122, 0.127) | (0.204, 0.212) | (0.667, 0.678) |\n",
      "| MLP | 0.826 | 0.264 | 0.708 | 0.800 | 0.143 | 0.238 | 0.754 |\n",
      "|  | (0.823, 0.829) | (0.257, 0.270) | (0.698, 0.718) | (0.797, 0.804) | (0.141, 0.145) | (0.235, 0.241) | (0.750, 0.758) |\n",
      "| RF | 0.844 | 0.280 | 0.244 | 0.982 | 0.395 | 0.302 | 0.613 |\n",
      "|  | (0.840, 0.847) | (0.275, 0.285) | (0.239, 0.250) | (0.982, 0.983) | (0.386, 0.405) | (0.295, 0.308) | (0.611, 0.616) |\n",
      "| SVM | 0.824 | 0.260 | 0.710 | 0.794 | 0.140 | 0.233 | 0.752 |\n",
      "|  | (0.820, 0.827) | (0.254, 0.266) | (0.702, 0.719) | (0.792, 0.795) | (0.138, 0.141) | (0.231, 0.235) | (0.748, 0.756) |\n",
      "| **Combined Data** | | | | | | | |\n",
      "| ASA Rule | 0.758 | 0.192 | 0.067 | 0.992 | 0.295 | 0.109 | 0.530 |\n",
      "|  | (0.755, 0.761) | (0.185, 0.199) | (0.063, 0.071) | (0.992, 0.993) | (0.280, 0.310) | (0.103, 0.116) | (0.528, 0.532) |\n",
      "| AutoGluon | 0.932 | 0.618 | 0.804 | 0.904 | 0.284 | 0.419 | 0.854 |\n",
      "|  | (0.930, 0.935) | (0.608, 0.627) | (0.795, 0.812) | (0.899, 0.908) | (0.275, 0.292) | (0.409, 0.428) | (0.851, 0.857) |\n",
      "| GBT | 0.930 | 0.636 | 0.531 | 0.989 | 0.696 | 0.602 | 0.760 |\n",
      "|  | (0.928, 0.932) | (0.631, 0.640) | (0.524, 0.538) | (0.989, 0.989) | (0.689, 0.702) | (0.597, 0.607) | (0.757, 0.763) |\n",
      "| KNN | 0.873 | 0.280 | 0.000 | 1.000 | 0.000 | 0.000 | 0.500 |\n",
      "|  | (0.871, 0.876) | (0.274, 0.286) | N/A | N/A | N/A | N/A | N/A |\n",
      "| LR | 0.917 | 0.544 | 0.804 | 0.888 | 0.252 | 0.384 | 0.846 |\n",
      "|  | (0.915, 0.920) | (0.538, 0.551) | (0.798, 0.811) | (0.886, 0.889) | (0.250, 0.254) | (0.381, 0.387) | (0.843, 0.849) |\n",
      "| MLP | 0.919 | 0.577 | 0.814 | 0.877 | 0.238 | 0.368 | 0.846 |\n",
      "|  | (0.917, 0.921) | (0.569, 0.584) | (0.808, 0.821) | (0.875, 0.879) | (0.235, 0.241) | (0.365, 0.372) | (0.843, 0.849) |\n",
      "| MLP+LSTM | 0.825 | 0.271 | 0.708 | 0.787 | 0.185 | 0.273 | 0.747 |\n",
      "|  | (0.800, 0.851) | (0.249, 0.293) | (0.615, 0.800) | (0.756, 0.819) | (0.170, 0.200) | (0.250, 0.296) | (0.715, 0.780) |\n",
      "| RF | 0.925 | 0.593 | 0.506 | 0.988 | 0.671 | 0.576 | 0.747 |\n",
      "|  | (0.923, 0.928) | (0.588, 0.599) | (0.500, 0.512) | (0.988, 0.989) | (0.664, 0.677) | (0.572, 0.581) | (0.744, 0.750) |\n",
      "| SVM | 0.918 | 0.536 | 0.820 | 0.875 | 0.235 | 0.366 | 0.848 |\n",
      "|  | (0.916, 0.920) | (0.529, 0.543) | (0.815, 0.826) | (0.874, 0.876) | (0.234, 0.237) | (0.363, 0.369) | (0.845, 0.850) |\n",
      "\n",
      "--- Rich Text Table (for Jupyter Notebook) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <table style=\"font-family: 'Times New Roman', Times, serif; font-size: 8pt; border-collapse: collapse; width: 100%; border: 1px solid #999;\">\n",
       "<thead>\n",
       "<tr>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">Model</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">AUROC</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">AUPRC</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">Sensitivity</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">Specificity</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">Precision</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">F-score</th>\n",
       "<th style=\"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\">Accuracy</th>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td colspan=\"8\" style=\"border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;\">Preop Data</td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">ASA Rule</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.758<br><span style=\"color: #444;\">(0.755, 0.761)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.192<br><span style=\"color: #444;\">(0.185, 0.199)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.067<br><span style=\"color: #444;\">(0.063, 0.071)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.992<br><span style=\"color: #444;\">(0.992, 0.993)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.295<br><span style=\"color: #444;\">(0.280, 0.310)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.109<br><span style=\"color: #444;\">(0.103, 0.116)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.530<br><span style=\"color: #444;\">(0.528, 0.532)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">AutoGluon</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.931<br><span style=\"color: #444;\">(0.928, 0.933)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.625<br><span style=\"color: #444;\">(0.618, 0.631)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.819<br><span style=\"color: #444;\">(0.811, 0.828)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.887<br><span style=\"color: #444;\">(0.883, 0.890)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.254<br><span style=\"color: #444;\">(0.250, 0.259)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.388<br><span style=\"color: #444;\">(0.383, 0.393)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.853<br><span style=\"color: #444;\">(0.850, 0.856)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">GBT</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.926<br><span style=\"color: #444;\">(0.924, 0.928)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.614<br><span style=\"color: #444;\">(0.609, 0.620)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.626<br><span style=\"color: #444;\">(0.620, 0.633)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.972<br><span style=\"color: #444;\">(0.971, 0.973)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.512<br><span style=\"color: #444;\">(0.506, 0.518)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.564<br><span style=\"color: #444;\">(0.559, 0.568)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.799<br><span style=\"color: #444;\">(0.796, 0.802)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">KNN</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.909<br><span style=\"color: #444;\">(0.907, 0.912)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.542<br><span style=\"color: #444;\">(0.535, 0.550)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.126<br><span style=\"color: #444;\">(0.121, 0.132)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">1.000<br><span style=\"color: #444;\">(1.000, 1.000)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.949<br><span style=\"color: #444;\">(0.939, 0.959)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.223<br><span style=\"color: #444;\">(0.214, 0.232)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.563<br><span style=\"color: #444;\">(0.560, 0.566)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">LR</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.912<br><span style=\"color: #444;\">(0.910, 0.915)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.532<br><span style=\"color: #444;\">(0.525, 0.539)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.804<br><span style=\"color: #444;\">(0.798, 0.810)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.878<br><span style=\"color: #444;\">(0.876, 0.879)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.236<br><span style=\"color: #444;\">(0.234, 0.238)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.365<br><span style=\"color: #444;\">(0.363, 0.368)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.841<br><span style=\"color: #444;\">(0.838, 0.844)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">MLP</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.919<br><span style=\"color: #444;\">(0.917, 0.921)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.588<br><span style=\"color: #444;\">(0.581, 0.594)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.813<br><span style=\"color: #444;\">(0.807, 0.820)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.875<br><span style=\"color: #444;\">(0.873, 0.878)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.235<br><span style=\"color: #444;\">(0.232, 0.238)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.365<br><span style=\"color: #444;\">(0.362, 0.368)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.844<br><span style=\"color: #444;\">(0.842, 0.847)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">RF</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.926<br><span style=\"color: #444;\">(0.923, 0.928)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.584<br><span style=\"color: #444;\">(0.578, 0.591)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.617<br><span style=\"color: #444;\">(0.610, 0.623)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.972<br><span style=\"color: #444;\">(0.971, 0.972)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.509<br><span style=\"color: #444;\">(0.504, 0.513)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.557<br><span style=\"color: #444;\">(0.553, 0.562)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.794<br><span style=\"color: #444;\">(0.791, 0.797)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">SVM</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.913<br><span style=\"color: #444;\">(0.910, 0.915)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.531<br><span style=\"color: #444;\">(0.524, 0.538)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.802<br><span style=\"color: #444;\">(0.795, 0.809)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.879<br><span style=\"color: #444;\">(0.878, 0.880)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.237<br><span style=\"color: #444;\">(0.236, 0.239)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.366<br><span style=\"color: #444;\">(0.364, 0.369)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.840<br><span style=\"color: #444;\">(0.837, 0.844)</span></td></tr>\n",
       "<tr><td colspan=\"8\" style=\"border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;\">Intraop Data</td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">AutoGluon</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.858<br><span style=\"color: #444;\">(0.854, 0.862)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.342<br><span style=\"color: #444;\">(0.334, 0.351)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.730<br><span style=\"color: #444;\">(0.715, 0.744)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.833<br><span style=\"color: #444;\">(0.828, 0.838)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.171<br><span style=\"color: #444;\">(0.168, 0.174)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.277<br><span style=\"color: #444;\">(0.273, 0.281)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.781<br><span style=\"color: #444;\">(0.775, 0.787)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">GBT</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.851<br><span style=\"color: #444;\">(0.847, 0.854)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.337<br><span style=\"color: #444;\">(0.331, 0.343)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.592<br><span style=\"color: #444;\">(0.582, 0.601)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.909<br><span style=\"color: #444;\">(0.907, 0.911)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.234<br><span style=\"color: #444;\">(0.231, 0.237)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.335<br><span style=\"color: #444;\">(0.331, 0.340)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.750<br><span style=\"color: #444;\">(0.746, 0.755)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">KNN</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.766<br><span style=\"color: #444;\">(0.763, 0.769)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.160<br><span style=\"color: #444;\">(0.156, 0.164)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">1.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.500</td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">LR</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.807<br><span style=\"color: #444;\">(0.804, 0.811)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.225<br><span style=\"color: #444;\">(0.220, 0.231)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.708<br><span style=\"color: #444;\">(0.699, 0.717)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.769<br><span style=\"color: #444;\">(0.766, 0.772)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.126<br><span style=\"color: #444;\">(0.125, 0.127)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.214<br><span style=\"color: #444;\">(0.212, 0.216)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.738<br><span style=\"color: #444;\">(0.734, 0.743)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">LSTM</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.739<br><span style=\"color: #444;\">(0.732, 0.745)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.210<br><span style=\"color: #444;\">(0.203, 0.217)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.628<br><span style=\"color: #444;\">(0.612, 0.644)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.717<br><span style=\"color: #444;\">(0.706, 0.729)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.125<br><span style=\"color: #444;\">(0.122, 0.127)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.208<br><span style=\"color: #444;\">(0.204, 0.212)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.673<br><span style=\"color: #444;\">(0.667, 0.678)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">MLP</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.826<br><span style=\"color: #444;\">(0.823, 0.829)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.264<br><span style=\"color: #444;\">(0.257, 0.270)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.708<br><span style=\"color: #444;\">(0.698, 0.718)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.800<br><span style=\"color: #444;\">(0.797, 0.804)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.143<br><span style=\"color: #444;\">(0.141, 0.145)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.238<br><span style=\"color: #444;\">(0.235, 0.241)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.754<br><span style=\"color: #444;\">(0.750, 0.758)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">RF</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.844<br><span style=\"color: #444;\">(0.840, 0.847)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.280<br><span style=\"color: #444;\">(0.275, 0.285)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.244<br><span style=\"color: #444;\">(0.239, 0.250)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.982<br><span style=\"color: #444;\">(0.982, 0.983)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.395<br><span style=\"color: #444;\">(0.386, 0.405)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.302<br><span style=\"color: #444;\">(0.295, 0.308)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.613<br><span style=\"color: #444;\">(0.611, 0.616)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">SVM</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.824<br><span style=\"color: #444;\">(0.820, 0.827)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.260<br><span style=\"color: #444;\">(0.254, 0.266)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.710<br><span style=\"color: #444;\">(0.702, 0.719)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.794<br><span style=\"color: #444;\">(0.792, 0.795)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.140<br><span style=\"color: #444;\">(0.138, 0.141)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.233<br><span style=\"color: #444;\">(0.231, 0.235)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.752<br><span style=\"color: #444;\">(0.748, 0.756)</span></td></tr>\n",
       "<tr><td colspan=\"8\" style=\"border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;\">Combined Data</td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">ASA Rule</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.758<br><span style=\"color: #444;\">(0.755, 0.761)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.192<br><span style=\"color: #444;\">(0.185, 0.199)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.067<br><span style=\"color: #444;\">(0.063, 0.071)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.992<br><span style=\"color: #444;\">(0.992, 0.993)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.295<br><span style=\"color: #444;\">(0.280, 0.310)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.109<br><span style=\"color: #444;\">(0.103, 0.116)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.530<br><span style=\"color: #444;\">(0.528, 0.532)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">AutoGluon</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.932<br><span style=\"color: #444;\">(0.930, 0.935)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.618<br><span style=\"color: #444;\">(0.608, 0.627)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.804<br><span style=\"color: #444;\">(0.795, 0.812)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.904<br><span style=\"color: #444;\">(0.899, 0.908)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.284<br><span style=\"color: #444;\">(0.275, 0.292)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.419<br><span style=\"color: #444;\">(0.409, 0.428)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.854<br><span style=\"color: #444;\">(0.851, 0.857)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">GBT</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.930<br><span style=\"color: #444;\">(0.928, 0.932)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.636<br><span style=\"color: #444;\">(0.631, 0.640)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.531<br><span style=\"color: #444;\">(0.524, 0.538)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.989<br><span style=\"color: #444;\">(0.989, 0.989)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.696<br><span style=\"color: #444;\">(0.689, 0.702)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.602<br><span style=\"color: #444;\">(0.597, 0.607)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.760<br><span style=\"color: #444;\">(0.757, 0.763)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">KNN</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.873<br><span style=\"color: #444;\">(0.871, 0.876)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.280<br><span style=\"color: #444;\">(0.274, 0.286)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">1.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.000</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.500</td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">LR</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.917<br><span style=\"color: #444;\">(0.915, 0.920)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.544<br><span style=\"color: #444;\">(0.538, 0.551)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.804<br><span style=\"color: #444;\">(0.798, 0.811)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.888<br><span style=\"color: #444;\">(0.886, 0.889)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.252<br><span style=\"color: #444;\">(0.250, 0.254)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.384<br><span style=\"color: #444;\">(0.381, 0.387)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.846<br><span style=\"color: #444;\">(0.843, 0.849)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">MLP</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.919<br><span style=\"color: #444;\">(0.917, 0.921)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.577<br><span style=\"color: #444;\">(0.569, 0.584)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.814<br><span style=\"color: #444;\">(0.808, 0.821)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.877<br><span style=\"color: #444;\">(0.875, 0.879)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.238<br><span style=\"color: #444;\">(0.235, 0.241)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.368<br><span style=\"color: #444;\">(0.365, 0.372)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.846<br><span style=\"color: #444;\">(0.843, 0.849)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">MLP+LSTM</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.825<br><span style=\"color: #444;\">(0.800, 0.851)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.271<br><span style=\"color: #444;\">(0.249, 0.293)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.708<br><span style=\"color: #444;\">(0.615, 0.800)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.787<br><span style=\"color: #444;\">(0.756, 0.819)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.185<br><span style=\"color: #444;\">(0.170, 0.200)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.273<br><span style=\"color: #444;\">(0.250, 0.296)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.747<br><span style=\"color: #444;\">(0.715, 0.780)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">RF</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.925<br><span style=\"color: #444;\">(0.923, 0.928)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.593<br><span style=\"color: #444;\">(0.588, 0.599)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.506<br><span style=\"color: #444;\">(0.500, 0.512)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.988<br><span style=\"color: #444;\">(0.988, 0.989)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.671<br><span style=\"color: #444;\">(0.664, 0.677)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.576<br><span style=\"color: #444;\">(0.572, 0.581)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.747<br><span style=\"color: #444;\">(0.744, 0.750)</span></td></tr>\n",
       "<tr><td style=\"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\">SVM</td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.918<br><span style=\"color: #444;\">(0.916, 0.920)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.536<br><span style=\"color: #444;\">(0.529, 0.543)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.820<br><span style=\"color: #444;\">(0.815, 0.826)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.875<br><span style=\"color: #444;\">(0.874, 0.876)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.235<br><span style=\"color: #444;\">(0.234, 0.237)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.366<br><span style=\"color: #444;\">(0.363, 0.369)</span></td><td style=\"border: 1px solid #999; padding: 6px; text-align: center;\">0.848<br><span style=\"color: #444;\">(0.845, 0.850)</span></td></tr>\n",
       "</tbody></table>\n",
       "        <br>\n",
       "        <a href=\"#\" onclick=\"document.getElementById('collapsible-3e884735ec454ceb8b99371455482f57').style.display = document.getElementById('collapsible-3e884735ec454ceb8b99371455482f57').style.display === 'none' ? 'block' : 'none'; return false;\">\n",
       "            Show/Hide HTML Source\n",
       "        </a>\n",
       "        <pre id=\"collapsible-3e884735ec454ceb8b99371455482f57\" style=\"display:none; background-color:#f8f8f8; border:1px solid #ccc; padding:10px; white-space: pre-wrap; word-wrap: break-word;\"><code>&lt;table style=&quot;font-family: &#x27;Times New Roman&#x27;, Times, serif; font-size: 8pt; border-collapse: collapse; width: 100%; border: 1px solid #999;&quot;&gt;\n",
       "&lt;thead&gt;\n",
       "&lt;tr&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;Model&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;AUROC&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;AUPRC&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;Sensitivity&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;Specificity&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;Precision&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;F-score&lt;/th&gt;\n",
       "&lt;th style=&quot;border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;&quot;&gt;Accuracy&lt;/th&gt;\n",
       "&lt;/tr&gt;\n",
       "&lt;/thead&gt;\n",
       "&lt;tbody&gt;\n",
       "&lt;tr&gt;&lt;td colspan=&quot;8&quot; style=&quot;border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;&quot;&gt;Preop Data&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;ASA Rule&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.758&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.755, 0.761)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.192&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.185, 0.199)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.067&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.063, 0.071)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.992&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.992, 0.993)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.295&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.280, 0.310)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.109&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.103, 0.116)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.530&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.528, 0.532)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;AutoGluon&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.931&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.928, 0.933)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.625&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.618, 0.631)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.819&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.811, 0.828)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.887&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.883, 0.890)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.254&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.250, 0.259)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.388&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.383, 0.393)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.853&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.850, 0.856)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;GBT&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.926&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.924, 0.928)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.614&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.609, 0.620)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.626&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.620, 0.633)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.972&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.971, 0.973)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.512&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.506, 0.518)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.564&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.559, 0.568)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.799&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.796, 0.802)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;KNN&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.909&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.907, 0.912)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.542&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.535, 0.550)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.126&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.121, 0.132)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;1.000&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(1.000, 1.000)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.949&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.939, 0.959)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.223&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.214, 0.232)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.563&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.560, 0.566)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;LR&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.912&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.910, 0.915)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.532&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.525, 0.539)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.804&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.798, 0.810)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.878&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.876, 0.879)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.236&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.234, 0.238)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.365&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.363, 0.368)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.841&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.838, 0.844)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;MLP&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.919&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.917, 0.921)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.588&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.581, 0.594)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.813&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.807, 0.820)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.875&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.873, 0.878)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.235&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.232, 0.238)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.365&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.362, 0.368)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.844&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.842, 0.847)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;RF&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.926&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.923, 0.928)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.584&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.578, 0.591)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.617&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.610, 0.623)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.972&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.971, 0.972)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.509&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.504, 0.513)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.557&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.553, 0.562)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.794&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.791, 0.797)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;SVM&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.913&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.910, 0.915)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.531&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.524, 0.538)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.802&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.795, 0.809)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.879&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.878, 0.880)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.237&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.236, 0.239)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.366&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.364, 0.369)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.840&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.837, 0.844)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td colspan=&quot;8&quot; style=&quot;border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;&quot;&gt;Intraop Data&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;AutoGluon&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.858&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.854, 0.862)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.342&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.334, 0.351)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.730&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.715, 0.744)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.833&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.828, 0.838)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.171&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.168, 0.174)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.277&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.273, 0.281)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.781&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.775, 0.787)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;GBT&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.851&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.847, 0.854)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.337&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.331, 0.343)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.592&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.582, 0.601)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.909&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.907, 0.911)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.234&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.231, 0.237)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.335&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.331, 0.340)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.750&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.746, 0.755)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;KNN&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.766&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.763, 0.769)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.160&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.156, 0.164)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;1.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.500&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;LR&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.807&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.804, 0.811)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.225&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.220, 0.231)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.708&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.699, 0.717)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.769&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.766, 0.772)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.126&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.125, 0.127)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.214&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.212, 0.216)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.738&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.734, 0.743)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;LSTM&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.739&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.732, 0.745)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.210&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.203, 0.217)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.628&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.612, 0.644)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.717&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.706, 0.729)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.125&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.122, 0.127)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.208&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.204, 0.212)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.673&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.667, 0.678)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;MLP&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.826&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.823, 0.829)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.264&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.257, 0.270)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.708&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.698, 0.718)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.800&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.797, 0.804)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.143&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.141, 0.145)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.238&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.235, 0.241)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.754&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.750, 0.758)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;RF&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.844&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.840, 0.847)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.280&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.275, 0.285)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.244&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.239, 0.250)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.982&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.982, 0.983)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.395&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.386, 0.405)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.302&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.295, 0.308)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.613&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.611, 0.616)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;SVM&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.824&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.820, 0.827)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.260&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.254, 0.266)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.710&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.702, 0.719)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.794&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.792, 0.795)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.140&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.138, 0.141)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.233&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.231, 0.235)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.752&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.748, 0.756)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td colspan=&quot;8&quot; style=&quot;border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;&quot;&gt;Combined Data&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;ASA Rule&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.758&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.755, 0.761)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.192&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.185, 0.199)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.067&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.063, 0.071)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.992&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.992, 0.993)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.295&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.280, 0.310)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.109&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.103, 0.116)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.530&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.528, 0.532)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;AutoGluon&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.932&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.930, 0.935)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.618&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.608, 0.627)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.804&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.795, 0.812)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.904&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.899, 0.908)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.284&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.275, 0.292)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.419&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.409, 0.428)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.854&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.851, 0.857)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;GBT&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.930&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.928, 0.932)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.636&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.631, 0.640)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.531&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.524, 0.538)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.989&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.989, 0.989)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.696&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.689, 0.702)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.602&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.597, 0.607)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.760&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.757, 0.763)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;KNN&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.873&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.871, 0.876)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.280&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.274, 0.286)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;1.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.000&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.500&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;LR&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.917&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.915, 0.920)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.544&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.538, 0.551)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.804&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.798, 0.811)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.888&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.886, 0.889)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.252&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.250, 0.254)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.384&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.381, 0.387)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.846&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.843, 0.849)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;MLP&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.919&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.917, 0.921)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.577&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.569, 0.584)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.814&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.808, 0.821)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.877&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.875, 0.879)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.238&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.235, 0.241)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.368&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.365, 0.372)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.846&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.843, 0.849)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;MLP+LSTM&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.825&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.800, 0.851)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.271&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.249, 0.293)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.708&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.615, 0.800)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.787&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.756, 0.819)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.185&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.170, 0.200)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.273&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.250, 0.296)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.747&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.715, 0.780)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;RF&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.925&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.923, 0.928)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.593&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.588, 0.599)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.506&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.500, 0.512)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.988&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.988, 0.989)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.671&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.664, 0.677)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.576&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.572, 0.581)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.747&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.744, 0.750)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;&quot;&gt;SVM&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.918&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.916, 0.920)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.536&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.529, 0.543)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.820&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.815, 0.826)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.875&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.874, 0.876)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.235&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.234, 0.237)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.366&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.363, 0.369)&lt;/span&gt;&lt;/td&gt;&lt;td style=&quot;border: 1px solid #999; padding: 6px; text-align: center;&quot;&gt;0.848&lt;br&gt;&lt;span style=&quot;color: #444;&quot;&gt;(0.845, 0.850)&lt;/span&gt;&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;/tbody&gt;&lt;/table&gt;</code></pre>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import html\n",
    "import uuid\n",
    "\n",
    "# =============================================================================\n",
    "# SCRIPT CONFIGURATION\n",
    "# =============================================================================\n",
    "# --- List of data sources to include in the table ---\n",
    "DATA_SOURCES = [\"preop\", \"intraop\", \"combined\"]\n",
    "\n",
    "# --- File Paths ---\n",
    "# IMPORTANT: Update this path to your actual results directory\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "OUTPUT_FILE = 'performance_table.md'\n",
    "\n",
    "# --- Model Name Translations for Plots ---\n",
    "# This ensures consistency with your main analysis script\n",
    "model_translate = {\n",
    "    'base': 'base', 'base_54k': 'base_54k',\n",
    "    'log_reg': 'LR', 'xgb': 'GBT',\n",
    "    'svm': 'SVM',\n",
    "    'mlp': 'MLP', 'rf': 'RF',\n",
    "    'knn': 'KNN', 'asa_rule': 'ASA Rule', 'autogluon': 'AutoGluon',\n",
    "    'lstm': 'LSTM', 'hybrid': 'MLP+LSTM'\n",
    "}\n",
    "\n",
    "# --- Base Model Mapping ---\n",
    "# Defines which ground-truth 'base' model to use for specific predictive models.\n",
    "model_base_map = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'MLP+LSTM': 'base_54k'\n",
    "}\n",
    "DEFAULT_BASE = 'base'\n",
    "\n",
    "\n",
    "# --- Metrics to include in the table and their display names ---\n",
    "# The order in this dictionary determines the column order in the table\n",
    "METRICS_MAP = {\n",
    "    'roc_auc': 'AUROC',\n",
    "    'pr_auc': 'AUPRC',\n",
    "    'recall': 'Sensitivity',\n",
    "    'specificity': 'Specificity',\n",
    "    'precision': 'Precision',\n",
    "    'f1': 'F-score',\n",
    "    'balanced_accuracy': 'Accuracy'\n",
    "}\n",
    "\n",
    "# =============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# =============================================================================\n",
    "\n",
    "def get_metric_ci(metric_array):\n",
    "    \"\"\"Calculates the mean and 95% CI for a given array of metric scores.\"\"\"\n",
    "    if metric_array is None or pd.isnull(metric_array).all() or len(np.atleast_1d(metric_array)) == 0:\n",
    "        return \"N/A\", \"N/A\"\n",
    "        \n",
    "    arr = np.atleast_1d(metric_array)\n",
    "    \n",
    "    if np.isscalar(arr) or len(arr) == 1:\n",
    "        mean_str = f\"{np.mean(arr):.3f}\"\n",
    "        ci_str = \"N/A\"\n",
    "    else:\n",
    "        mean = np.mean(arr)\n",
    "        sem = stats.sem(arr)\n",
    "        n = len(arr)\n",
    "        mean_str = f\"{mean:.3f}\"\n",
    "\n",
    "        if sem > 0 and n > 1:\n",
    "            ci = stats.t.interval(0.95, df=n-1, loc=mean, scale=sem)\n",
    "            ci_str = f\"({ci[0]:.3f}, {ci[1]:.3f})\"\n",
    "        else:\n",
    "            ci_str = \"N/A\"\n",
    "            \n",
    "    return mean_str, ci_str\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN SCRIPT LOGIC\n",
    "# =============================================================================\n",
    "\n",
    "def generate_performance_tables():\n",
    "    \"\"\"\n",
    "    Generates and displays performance tables in both Markdown and rich-text HTML format,\n",
    "    with inline styles for easy copy-pasting to Google Docs.\n",
    "    \"\"\"\n",
    "    all_results = {}\n",
    "    base_models_data = {}\n",
    "\n",
    "    # --- 1. Load data from all specified sources ---\n",
    "    for source in DATA_SOURCES:\n",
    "        pkl_path = os.path.join(RESULTS_DIR, f\"tabular_{source}_test.pkl\")\n",
    "        try:\n",
    "            df = pd.read_pickle(pkl_path)\n",
    "            df['model_name'] = df['model_name'].map(model_translate)\n",
    "            df.dropna(subset=['model_name'], inplace=True)\n",
    "            \n",
    "            df_models = df[~df['model_name'].str.contains('base', na=False)].copy()\n",
    "            df_base = df[df['model_name'].str.contains('base', na=False)].copy()\n",
    "            \n",
    "            all_results[source] = df_models\n",
    "            \n",
    "            for _, base_row in df_base.iterrows():\n",
    "                # Assuming 'y_pred_binary' for base models holds the true labels for each run\n",
    "                base_models_data[base_row['model_name']] = base_row['y_pred_binary']\n",
    "                \n",
    "            print(f\"Successfully loaded data for: {source.upper()}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"WARNING: Results file not found for '{source}'. Skipping.\")\n",
    "            continue\n",
    "\n",
    "    # --- 2. Initialize Markdown and define HTML table styles ---\n",
    "    # --- Markdown Initialization ---\n",
    "    markdown_lines = []\n",
    "    md_header = \"| Model | \" + \" | \".join(METRICS_MAP.values()) + \" |\"\n",
    "    md_separator = \"|\" + \"---|\" * (len(METRICS_MAP) + 1)\n",
    "    markdown_lines.extend([md_header, md_separator])\n",
    "\n",
    "    # --- HTML Styling for Google Docs ---\n",
    "    table_style = \"font-family: 'Times New Roman', Times, serif; font-size: 8pt; border-collapse: collapse; width: 100%; border: 1px solid #999;\"\n",
    "    th_style = \"border: 1px solid #999; padding: 6px; text-align: center; background-color: #f2f2f2; font-weight: bold;\"\n",
    "    section_header_style = \"border: 1px solid #999; padding: 6px; text-align: left; background-color: #e0e0e0; font-weight: bold;\"\n",
    "    model_name_style = \"border: 1px solid #999; padding: 6px; text-align: left; font-weight: bold;\"\n",
    "    cell_style = \"border: 1px solid #999; padding: 6px; text-align: center;\"\n",
    "    ci_style = \"color: #444;\" # Style for the confidence interval text\n",
    "\n",
    "    # --- HTML Initialization ---\n",
    "    html_lines = [f'<table style=\"{table_style}\">', '<thead>', '<tr>']\n",
    "    html_lines.append(f'<th style=\"{th_style}\">Model</th>')\n",
    "    for name in METRICS_MAP.values():\n",
    "        html_lines.append(f'<th style=\"{th_style}\">{name}</th>')\n",
    "    html_lines.extend(['</tr>', '</thead>', '<tbody>'])\n",
    "\n",
    "\n",
    "    # --- 3. Populate tables section by section ---\n",
    "    for source_name, df_data in all_results.items():\n",
    "        # Add section titles\n",
    "        section_title_text = f\"**{source_name.replace('_', ' ').title()} Data**\"\n",
    "        markdown_lines.append(f\"| {section_title_text} |\" + \" |\" * len(METRICS_MAP))\n",
    "        html_lines.append(f'<tr><td colspan=\"{len(METRICS_MAP)+1}\" style=\"{section_header_style}\">{section_title_text.replace(\"**\",\"\")}</td></tr>')\n",
    "\n",
    "        df_data = df_data.sort_values(by='model_name')\n",
    "\n",
    "        for _, model_row in df_data.iterrows():\n",
    "            model_name = model_row['model_name']\n",
    "            \n",
    "            # --- Calculate metrics ---\n",
    "            final_metrics = {key: model_row.get(key) for key in METRICS_MAP.keys()}\n",
    "            if 'pr_auc' in final_metrics and (final_metrics['pr_auc'] is None or np.all(pd.isnull(final_metrics['pr_auc']))):\n",
    "                auprc_scores = []\n",
    "                base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "                if base_to_use in base_models_data:\n",
    "                    y_true_runs = base_models_data[base_to_use]\n",
    "                    y_prob_runs = model_row.get('y_prob')\n",
    "                    if y_prob_runs is not None:\n",
    "                        for i in range(len(y_prob_runs)):\n",
    "                            if i < len(y_true_runs) and len(y_true_runs[i]) == len(y_prob_runs[i]):\n",
    "                                precision, recall, _ = precision_recall_curve(y_true_runs[i], y_prob_runs[i])\n",
    "                                auprc_scores.append(auc(recall, precision))\n",
    "                final_metrics['pr_auc'] = auprc_scores if auprc_scores else None\n",
    "\n",
    "            # --- Build Markdown Rows ---\n",
    "            md_mean_values = [model_name]\n",
    "            md_ci_values = [\"\"]\n",
    "            \n",
    "            # --- Build HTML Row ---\n",
    "            html_row_cells = [f'<td style=\"{model_name_style}\">{model_name}</td>']\n",
    "\n",
    "            for metric_key in METRICS_MAP.keys():\n",
    "                mean_str, ci_str = get_metric_ci(final_metrics.get(metric_key))\n",
    "                \n",
    "                md_mean_values.append(mean_str)\n",
    "                md_ci_values.append(ci_str)\n",
    "                \n",
    "                # HTML cell with inline styles\n",
    "                html_cell = f'{mean_str}<br><span style=\"{ci_style}\">{ci_str}</span>' if ci_str != \"N/A\" else mean_str\n",
    "                html_row_cells.append(f'<td style=\"{cell_style}\">{html_cell}</td>')\n",
    "\n",
    "            markdown_lines.append(\"| \" + \" | \".join(md_mean_values) + \" |\")\n",
    "            markdown_lines.append(\"| \" + \" | \".join(md_ci_values) + \" |\")\n",
    "            html_lines.append(\"<tr>\" + \"\".join(html_row_cells) + \"</tr>\")\n",
    "    \n",
    "    html_lines.append(\"</tbody></table>\")\n",
    "    \n",
    "    # --- 4. Finalize and Output ---\n",
    "    # --- Markdown Output ---\n",
    "    final_markdown = \"\\n\".join(markdown_lines)\n",
    "    try:\n",
    "        with open(OUTPUT_FILE, 'w') as f:\n",
    "            f.write(final_markdown)\n",
    "        print(f\"\\nSuccessfully saved Markdown table to: {OUTPUT_FILE}\")\n",
    "    except IOError as e:\n",
    "        print(f\"\\nERROR: Could not save Markdown file. {e}\")\n",
    "        \n",
    "    print(\"\\n--- Generated Markdown Table ---\\n\")\n",
    "    print(final_markdown)\n",
    "    \n",
    "    # --- HTML Output (for Jupyter) ---\n",
    "    table_html = \"\\n\".join(html_lines)\n",
    "    \n",
    "    collapsible_id = f\"collapsible-{uuid.uuid4().hex}\"\n",
    "    escaped_html = html.escape(table_html)\n",
    "    \n",
    "    full_html_output = f\"\"\"\n",
    "    <div>\n",
    "        {table_html}\n",
    "        <br>\n",
    "        <a href=\"#\" onclick=\"document.getElementById('{collapsible_id}').style.display = document.getElementById('{collapsible_id}').style.display === 'none' ? 'block' : 'none'; return false;\">\n",
    "            Show/Hide HTML Source\n",
    "        </a>\n",
    "        <pre id=\"{collapsible_id}\" style=\"display:none; background-color:#f8f8f8; border:1px solid #ccc; padding:10px; white-space: pre-wrap; word-wrap: break-word;\"><code>{escaped_html}</code></pre>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        from IPython.display import display, HTML\n",
    "        print(\"\\n--- Rich Text Table (for Jupyter Notebook) ---\")\n",
    "        display(HTML(full_html_output))\n",
    "    except ImportError:\n",
    "        print(\"\\n--- HTML Output (for non-Jupyter environments) ---\")\n",
    "        print(\"To see the rich text table, run this script in a Jupyter Notebook or open the saved HTML file.\")\n",
    "        try:\n",
    "            html_file_name = OUTPUT_FILE.replace('.md', '.html')\n",
    "            with open(html_file_name, 'w', encoding='utf-8') as f:\n",
    "                f.write(full_html_output)\n",
    "            print(f\"HTML table saved to: {html_file_name}\")\n",
    "        except IOError as e:\n",
    "                print(f\"\\nERROR: Could not save HTML file. {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_performance_tables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reclassification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING PATIENT RECLASSIFICATION ANALYSIS\n",
      "================================================================================\n",
      "Found 7 models common to all datasets.\n",
      "\n",
      "--- Analyzing Model: AutoGluon ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 80.1 patients.\n",
      "  This represents a 54.2% correction rate of the 147.9 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 10.3 patients.\n",
      "  This represents a 10.4% correction rate of the 98.7 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: GBT ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 92.0 patients.\n",
      "  This represents a 41.2% correction rate of the 223.2 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 7.9 patients.\n",
      "  This represents a 3.9% correction rate of the 204.2 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: KNN ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 69.1 patients.\n",
      "  This represents a 12.6% correction rate of the 546.8 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 0.0 patients.\n",
      "  This represents a 0.0% correction rate of the 477.7 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: Logistic Regression ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 90.8 patients.\n",
      "  This represents a 56.9% correction rate of the 159.6 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 16.0 patients.\n",
      "  This represents a 15.0% correction rate of the 107.0 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: MLP ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 94.0 patients.\n",
      "  This represents a 58.8% correction rate of the 159.8 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 21.4 patients.\n",
      "  This represents a 21.0% correction rate of the 102.0 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: Random Forest ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 230.8 patients.\n",
      "  This represents a 55.9% correction rate of the 413.2 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 4.9 patients.\n",
      "  This represents a 2.3% correction rate of the 209.6 initially missed positive cases per fold.\n",
      "\n",
      "--- Analyzing Model: SVM (Linear) ---\n",
      "Going from INTRAOP to PREOP:\n",
      "  The model correctly reclassified an average of 89.2 patients.\n",
      "  This represents a 56.3% correction rate of the 158.4 initially missed positive cases per fold.\n",
      "Going from PREOP to COMBINED:\n",
      "  The model correctly reclassified an average of 21.3 patients.\n",
      "  This represents a 19.7% correction rate of the 108.3 initially missed positive cases per fold.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"report-section\">\n",
       "        <h3>Patient Reclassification Analysis</h3>\n",
       "        <p>The table below shows the correction rate of initially missed positive cases (false negatives).</p>\n",
       "        \n",
       "    <style>\n",
       "        .results-table { border-collapse: collapse; width: 95%; margin-top: 15px; font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica, Arial, sans-serif; font-size: 14px; }\n",
       "        .results-table th, .results-table td { border: 1px solid #dee2e6; padding: 10px; text-align: center; }\n",
       "        .results-table thead th { background-color: #e9ecef; color: #495057; }\n",
       "        .results-table tbody tr:nth-child(even) { background-color: #f8f9fa; }\n",
       "        .results-table .model-name { text-align: left; font-weight: bold; }\n",
       "        .widget-container { margin-top: 20px; }\n",
       "        .toggle-link { color: #007bff; text-decoration: none; font-size: 14px; cursor: pointer; }\n",
       "        .toggle-link:hover { text-decoration: underline; }\n",
       "        .code-block { display: none; background-color: #f1f1f1; border: 1px solid #ccc; padding: 10px; margin-top: 10px; border-radius: 4px; white-space: pre-wrap; word-wrap: break-word; }\n",
       "    </style>\n",
       "        \n",
       "    <table class=\"results-table\">\n",
       "        <thead><tr><th>Model</th><th>Correction Rate: Intraop  Preop</th><th>Correction Rate: Preop  Combined</th></tr></thead>\n",
       "        <tbody><tr><td><strong>AutoGluon</strong></td><td>54.2% (80.1 / 147.9)</td><td>10.4% (10.3 / 98.7)</td></tr>\n",
       "<tr><td><strong>GBT</strong></td><td>41.2% (92.0 / 223.2)</td><td>3.9% (7.9 / 204.2)</td></tr>\n",
       "<tr><td><strong>KNN</strong></td><td>12.6% (69.1 / 546.8)</td><td>0.0% (0.0 / 477.7)</td></tr>\n",
       "<tr><td><strong>Logistic Regression</strong></td><td>56.9% (90.8 / 159.6)</td><td>15.0% (16.0 / 107.0)</td></tr>\n",
       "<tr><td><strong>MLP</strong></td><td>58.8% (94.0 / 159.8)</td><td>21.0% (21.4 / 102.0)</td></tr>\n",
       "<tr><td><strong>Random Forest</strong></td><td>55.9% (230.8 / 413.2)</td><td>2.3% (4.9 / 209.6)</td></tr>\n",
       "<tr><td><strong>SVM (Linear)</strong></td><td>56.3% (89.2 / 158.4)</td><td>19.7% (21.3 / 108.3)</td></tr></tbody>\n",
       "    </table>\n",
       "        <div class=\"widget-container\">\n",
       "            <a class=\"toggle-link\" onclick=\"var x = document.getElementById('widget_3cd55bece940843c'); x.style.display = (x.style.display === 'none' ? 'block' : 'none');\">\n",
       "                Show/Hide HTML Source\n",
       "            </a>\n",
       "            <pre id=\"widget_3cd55bece940843c\" class=\"code-block\"><code>\n",
       "    &lt;table class=&quot;results-table&quot;&gt;\n",
       "        &lt;thead&gt;&lt;tr&gt;&lt;th&gt;Model&lt;/th&gt;&lt;th&gt;Correction Rate: Intraop  Preop&lt;/th&gt;&lt;th&gt;Correction Rate: Preop  Combined&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;\n",
       "        &lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;AutoGluon&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;54.2% (80.1 / 147.9)&lt;/td&gt;&lt;td&gt;10.4% (10.3 / 98.7)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;GBT&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;41.2% (92.0 / 223.2)&lt;/td&gt;&lt;td&gt;3.9% (7.9 / 204.2)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;KNN&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;12.6% (69.1 / 546.8)&lt;/td&gt;&lt;td&gt;0.0% (0.0 / 477.7)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Logistic Regression&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;56.9% (90.8 / 159.6)&lt;/td&gt;&lt;td&gt;15.0% (16.0 / 107.0)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;MLP&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;58.8% (94.0 / 159.8)&lt;/td&gt;&lt;td&gt;21.0% (21.4 / 102.0)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Random Forest&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;55.9% (230.8 / 413.2)&lt;/td&gt;&lt;td&gt;2.3% (4.9 / 209.6)&lt;/td&gt;&lt;/tr&gt;\n",
       "&lt;tr&gt;&lt;td&gt;&lt;strong&gt;SVM (Linear)&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;56.3% (89.2 / 158.4)&lt;/td&gt;&lt;td&gt;19.7% (21.3 / 108.3)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;\n",
       "    &lt;/table&gt;</code></pre>\n",
       "        </div>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RECLASSIFICATION ANALYSIS COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import html\n",
    "from IPython.display import display, HTML\n",
    "import scipy.stats as stats\n",
    "\n",
    "# =============================================================================\n",
    "# SCRIPT CONFIGURATION\n",
    "# =============================================================================\n",
    "# --- Analysis Settings ---\n",
    "N_FOLDS = 25 # Number of cross-validation folds\n",
    "\n",
    "# --- Paths and Naming ---\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "\n",
    "# --- Model Name Translations ---\n",
    "model_translate = {\n",
    "    'base': 'base', 'base_54k': 'base_54k',\n",
    "    'log_reg': 'Logistic Regression', 'xgb': 'GBT',\n",
    "    'svm': 'SVM (Linear)',\n",
    "    'mlp': 'MLP', 'rf': 'Random Forest',\n",
    "    'knn': 'KNN', 'asa_rule': 'ASA Rule', 'autogluon': 'AutoGluon',\n",
    "    'lstm': 'LSTM', 'hybrid': 'Hybrid (MLP + LSTM)'\n",
    "}\n",
    "\n",
    "# --- Base Model Mapping ---\n",
    "model_base_map = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'Hybrid (MLP + LSTM)': 'base_54k'\n",
    "}\n",
    "DEFAULT_BASE = 'base'\n",
    "\n",
    "# =============================================================================\n",
    "# RECLASSIFICATION ANALYSIS\n",
    "# =============================================================================\n",
    "\n",
    "def load_for_reclassification(data_source):\n",
    "    \"\"\"Loads and processes data specifically for the reclassification analysis.\"\"\"\n",
    "    output_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test.pkl\")\n",
    "    try:\n",
    "        df = pd.read_pickle(output_pkl)\n",
    "        df['model_name'] = df['model_name'].map(model_translate)\n",
    "        df.dropna(subset=['model_name'], inplace=True)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Reclassification analysis - Results file not found at {output_pkl}.\")\n",
    "        return None\n",
    "    \n",
    "    processed_data = {}\n",
    "    base_names = [name for name in df['model_name'].unique() if 'base' in name]\n",
    "    if not base_names: return None\n",
    "    base_models_data = {name: np.concatenate(df[df['model_name'] == name]['y_pred_binary'].values[0]) for name in base_names}\n",
    "    df_to_process = df[~df['model_name'].str.contains('base')]\n",
    "    for _, model_row in df_to_process.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        base_to_use = model_base_map.get(model_name, DEFAULT_BASE)\n",
    "        if base_to_use not in base_models_data: continue\n",
    "        y_true_flat = base_models_data[base_to_use]\n",
    "        y_pred_flat = np.concatenate(model_row['y_pred_binary'])\n",
    "        if len(y_true_flat) == len(y_pred_flat):\n",
    "            processed_data[model_name] = {'y_true': y_true_flat, 'y_pred': y_pred_flat}\n",
    "    return processed_data\n",
    "\n",
    "def display_reclassification_report(results_data):\n",
    "    \"\"\"Displays the reclassification report in the notebook.\"\"\"\n",
    "    table_rows = []\n",
    "    for result in results_data:\n",
    "        model_name = result['model_name']\n",
    "        rate1, reclassified1, missed1 = result['intraop_to_preop'].values()\n",
    "        rate2, reclassified2, missed2 = result['preop_to_combined'].values()\n",
    "        cell1 = f\"<td>{rate1:.1f}% ({reclassified1:.1f} / {missed1:.1f})</td>\"\n",
    "        cell2 = f\"<td>{rate2:.1f}% ({reclassified2:.1f} / {missed2:.1f})</td>\"\n",
    "        table_rows.append(f\"<tr><td><strong>{model_name}</strong></td>{cell1}{cell2}</tr>\")\n",
    "\n",
    "    table_body_html = \"\\n\".join(table_rows)\n",
    "    table_html = f\"\"\"\n",
    "    <table class=\"results-table\">\n",
    "        <thead><tr><th>Model</th><th>Correction Rate: Intraop  Preop</th><th>Correction Rate: Preop  Combined</th></tr></thead>\n",
    "        <tbody>{table_body_html}</tbody>\n",
    "    </table>\"\"\"\n",
    "    display_html_with_widget(\"Patient Reclassification Analysis\", \"The table below shows the correction rate of initially missed positive cases (false negatives).\", table_html)\n",
    "\n",
    "def analyze_patient_reclassification():\n",
    "    \"\"\"Performs and displays the reclassification analysis.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\nSTARTING PATIENT RECLASSIFICATION ANALYSIS\\n\" + \"=\"*80)\n",
    "    sources = [\"intraop\", \"preop\", \"combined\"]\n",
    "    all_data = {source: load_for_reclassification(source) for source in sources}\n",
    "    if any(data is None for data in all_data.values()): return\n",
    "\n",
    "    model_sets = [set(data.keys()) for data in all_data.values()]\n",
    "    common_models = sorted(list(set.intersection(*model_sets)))\n",
    "    if not common_models: \n",
    "        print(\"No models found in common across all datasets.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(common_models)} models common to all datasets.\")\n",
    "    \n",
    "    results_for_html = []\n",
    "    for model_name in common_models:\n",
    "        print(f\"\\n--- Analyzing Model: {model_name} ---\")\n",
    "        model_results = {'model_name': model_name}\n",
    "        for source_before, source_after in [(\"intraop\", \"preop\"), (\"preop\", \"combined\")]:\n",
    "            data_before = all_data[source_before][model_name]\n",
    "            data_after = all_data[source_after][model_name]\n",
    "            y_true, pred_before, pred_after = data_before['y_true'], data_before['y_pred'], data_after['y_pred']\n",
    "            \n",
    "            was_fn = (y_true == 1) & (pred_before == 0)\n",
    "            is_tp_now = (y_true == 1) & (pred_after == 1)\n",
    "            \n",
    "            total_reclassified = np.sum(was_fn & is_tp_now)\n",
    "            total_fn = np.sum(was_fn)\n",
    "            \n",
    "            avg_reclassified = total_reclassified / N_FOLDS\n",
    "            avg_false_negatives = total_fn / N_FOLDS\n",
    "            \n",
    "            rate = (total_reclassified / total_fn) * 100 if total_fn > 0 else 0.0\n",
    "            \n",
    "            print(\n",
    "                f\"Going from {source_before.upper()} to {source_after.upper()}:\\n\"\n",
    "                f\"  The model correctly reclassified an average of {avg_reclassified:.1f} patients.\\n\"\n",
    "                f\"  This represents a {rate:.1f}% correction rate of the \"\n",
    "                f\"{avg_false_negatives:.1f} initially missed positive cases per fold.\"\n",
    "            )\n",
    "\n",
    "            model_results[f\"{source_before}_to_{source_after}\"] = {\n",
    "                'rate': rate, 'reclassified': avg_reclassified, 'missed': avg_false_negatives\n",
    "            }\n",
    "        results_for_html.append(model_results)\n",
    "    \n",
    "    # Display the final HTML table after printing all calculations\n",
    "    display_reclassification_report(results_for_html)\n",
    "\n",
    "# =============================================================================\n",
    "# GENERIC HTML DISPLAY WIDGET\n",
    "# =============================================================================\n",
    "\n",
    "def display_html_with_widget(title, description, table_html):\n",
    "    \"\"\"A generic function to display any HTML table with a collapsible code widget.\"\"\"\n",
    "    style = \"\"\"\n",
    "    <style>\n",
    "        .results-table { border-collapse: collapse; width: 95%; margin-top: 15px; font-family: -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, Helvetica, Arial, sans-serif; font-size: 14px; }\n",
    "        .results-table th, .results-table td { border: 1px solid #dee2e6; padding: 10px; text-align: center; }\n",
    "        .results-table thead th { background-color: #e9ecef; color: #495057; }\n",
    "        .results-table tbody tr:nth-child(even) { background-color: #f8f9fa; }\n",
    "        .results-table .model-name { text-align: left; font-weight: bold; }\n",
    "        .widget-container { margin-top: 20px; }\n",
    "        .toggle-link { color: #007bff; text-decoration: none; font-size: 14px; cursor: pointer; }\n",
    "        .toggle-link:hover { text-decoration: underline; }\n",
    "        .code-block { display: none; background-color: #f1f1f1; border: 1px solid #ccc; padding: 10px; margin-top: 10px; border-radius: 4px; white-space: pre-wrap; word-wrap: break-word; }\n",
    "    </style>\"\"\"\n",
    "    \n",
    "    unique_id = \"widget_\" + os.urandom(8).hex()\n",
    "    escaped_html = html.escape(table_html)\n",
    "    \n",
    "    full_html = f\"\"\"\n",
    "    <div class=\"report-section\">\n",
    "        <h3>{title}</h3>\n",
    "        <p>{description}</p>\n",
    "        {style}\n",
    "        {table_html}\n",
    "        <div class=\"widget-container\">\n",
    "            <a class=\"toggle-link\" onclick=\"var x = document.getElementById('{unique_id}'); x.style.display = (x.style.display === 'none' ? 'block' : 'none');\">\n",
    "                Show/Hide HTML Source\n",
    "            </a>\n",
    "            <pre id=\"{unique_id}\" class=\"code-block\"><code>{escaped_html}</code></pre>\n",
    "        </div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    display(HTML(full_html))\n",
    "\n",
    "# =============================================================================\n",
    "# MAIN EXECUTION BLOCK\n",
    "# =============================================================================\n",
    "\n",
    "def run_all_analyses():\n",
    "    \"\"\"Runs all analysis functions to generate a complete report.\"\"\"\n",
    "    analyze_patient_reclassification()\n",
    "    print(\"\\n\" + \"=\"*80 + \"\\nRECLASSIFICATION ANALYSIS COMPLETE\\n\" + \"=\"*80)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # In a script, you would call this.\n",
    "    run_all_analyses()\n",
    "\n",
    "# To run this in a Jupyter cell, you would call the main function directly:\n",
    "# run_all_analyses()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap CI and DCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING BOOTSTRAP AND DECISION-CURVE ANALYSIS (B=1000)\n",
      "================================================================================\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ PROCESSING: PREOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Analyzing model: Logistic Regression\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_Logistic_Regression.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_Logistic_Regression.csv\n",
      "Analyzing model: GBT\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_GBT.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_GBT.csv\n",
      "Analyzing model: Random Forest\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_Random_Forest.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_Random_Forest.csv\n",
      "Analyzing model: SVM (Linear)\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_SVM_Linear.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_SVM_Linear.csv\n",
      "Analyzing model: MLP\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_MLP.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_MLP.csv\n",
      "Analyzing model: KNN\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_KNN.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_KNN.csv\n",
      "Analyzing model: ASA Rule\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_ASA_Rule.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_ASA_Rule.csv\n",
      "Analyzing model: AutoGluon\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_preop_AutoGluon.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_preop_AutoGluon.csv\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ PROCESSING: INTRAOP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Analyzing model: Logistic Regression\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_Logistic_Regression.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_Logistic_Regression.csv\n",
      "Analyzing model: GBT\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_GBT.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_GBT.csv\n",
      "Analyzing model: Random Forest\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_Random_Forest.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_Random_Forest.csv\n",
      "Analyzing model: SVM (Linear)\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_SVM_Linear.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_SVM_Linear.csv\n",
      "Analyzing model: MLP\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_MLP.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_MLP.csv\n",
      "Analyzing model: KNN\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_KNN.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_KNN.csv\n",
      "Analyzing model: LSTM\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_LSTM.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_LSTM.csv\n",
      "Analyzing model: AutoGluon\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_intraop_AutoGluon.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_intraop_AutoGluon.csv\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ PROCESSING: COMBINED ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "Analyzing model: Logistic Regression\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_Logistic_Regression.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_Logistic_Regression.csv\n",
      "Analyzing model: GBT\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_GBT.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_GBT.csv\n",
      "Analyzing model: Random Forest\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_Random_Forest.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_Random_Forest.csv\n",
      "Analyzing model: SVM (Linear)\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_SVM_Linear.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_SVM_Linear.csv\n",
      "Analyzing model: MLP\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_MLP.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_MLP.csv\n",
      "Analyzing model: KNN\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_KNN.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_KNN.csv\n",
      "Analyzing model: ASA Rule\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_ASA_Rule.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_ASA_Rule.csv\n",
      "Analyzing model: Hybrid (MLP + LSTM)\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_Hybrid_MLP_+_LSTM.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_Hybrid_MLP_+_LSTM.csv\n",
      "Analyzing model: AutoGluon\n",
      "  -> Completed bootstrap CI calculation.\n",
      "  -> Saved DCA plot to: figures/dca/dca_curve_combined_AutoGluon.png\n",
      "  -> Saved DCA data to: figures/dca/dca_table_combined_AutoGluon.csv\n",
      "\n",
      "================================================================================\n",
      "ANALYSIS COMPLETE\n",
      "================================================================================\n",
      "Successfully saved all bootstrap confidence intervals to: metrics_ci.csv\n",
      "\n",
      "Final Results Preview:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_source</th>\n",
       "      <th>model_name</th>\n",
       "      <th>metric</th>\n",
       "      <th>point_estimate</th>\n",
       "      <th>lower_95_ci</th>\n",
       "      <th>upper_95_ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>preop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>auroc</td>\n",
       "      <td>0.911400</td>\n",
       "      <td>0.908674</td>\n",
       "      <td>0.914068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>preop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>auprc</td>\n",
       "      <td>0.526227</td>\n",
       "      <td>0.517332</td>\n",
       "      <td>0.535033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>preop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f2</td>\n",
       "      <td>0.577690</td>\n",
       "      <td>0.571446</td>\n",
       "      <td>0.584188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>preop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>brier</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.028997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>preop</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>calib_int</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  data_source           model_name     metric  point_estimate  lower_95_ci  \\\n",
       "0       preop  Logistic Regression      auroc        0.911400     0.908674   \n",
       "1       preop  Logistic Regression      auprc        0.526227     0.517332   \n",
       "2       preop  Logistic Regression         f2        0.577690     0.571446   \n",
       "3       preop  Logistic Regression      brier        0.028542     0.028065   \n",
       "4       preop  Logistic Regression  calib_int             NaN          NaN   \n",
       "\n",
       "   upper_95_ci  \n",
       "0     0.914068  \n",
       "1     0.535033  \n",
       "2     0.584188  \n",
       "3     0.028997  \n",
       "4          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CLINICAL UTILITY ANALYSIS (BOOTSTRAP CI & DECISION-CURVE ANALYSIS)\n",
    "#\n",
    "# This cell orchestrates the new analyses by:\n",
    "# 1. Importing the required functions from the new .py modules.\n",
    "# 2. Looping through each data source (preop, intraop, combined).\n",
    "# 3. Loading the corresponding CALIBRATED results file.\n",
    "# 4. For each model, it prepares the data and calls the bootstrap and DCA functions.\n",
    "# 5. Aggregates all bootstrap results and saves them to 'metrics_ci.csv'.\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 1. Import the new analysis functions\n",
    "from bootstrap_metrics import bootstrap_metrics\n",
    "from decision_curve import generate_dca_plot\n",
    "\n",
    "# 2. Configuration\n",
    "ALL_DATA_SOURCES = [\"preop\", \"intraop\", \"combined\"]\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "DCA_FIGURES_DIR = 'figures/dca' # Define the new save directory for DCA outputs\n",
    "\n",
    "# --- Set bootstrap repetitions ---\n",
    "# Standard value for publication is 1000.\n",
    "# Lower this value (e.g., to 100) for faster development runs.\n",
    "BOOTSTRAP_REPS = 1000 \n",
    "\n",
    "DEFAULT_BASE = 'base'\n",
    "MODEL_BASE_MAP = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'Hybrid (MLP + LSTM)': 'base_54k'\n",
    "}\n",
    "\n",
    "# Initialize a list to store all bootstrap results\n",
    "all_bootstrap_results = []\n",
    "\n",
    "print(f\"{'='*80}\\nSTARTING BOOTSTRAP AND DECISION-CURVE ANALYSIS (B={BOOTSTRAP_REPS})\\n{'='*80}\")\n",
    "\n",
    "# 3. Outer Loop: Iterate through data sources\n",
    "for data_source in ALL_DATA_SOURCES:\n",
    "    print(f\"\\n{'~'*25} PROCESSING: {data_source.upper()} {'~'*25}\\n\")\n",
    "    \n",
    "    # Construct path to the CALIBRATED results file\n",
    "    input_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test_calibrated.pkl\")\n",
    "    \n",
    "    try:\n",
    "        with open(input_pkl, 'rb') as f:\n",
    "            df_calibrated = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"ERROR: Calibrated results file not found at {input_pkl}. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    # Separate base (ground truth) and predictive models\n",
    "    df_base = df_calibrated[df_calibrated['model_name'].str.contains('base', na=False)].copy()\n",
    "    df_models = df_calibrated[~df_calibrated['model_name'].str.contains('base', na=False)].copy()\n",
    "\n",
    "    # 4. Inner Loop: Iterate through each model\n",
    "    for _, model_row in df_models.iterrows():\n",
    "        model_name = model_row['model_name']\n",
    "        print(f\"Analyzing model: {model_name}\")\n",
    "\n",
    "        # 5. Data Preparation\n",
    "        base_to_use = MODEL_BASE_MAP.get(model_name, DEFAULT_BASE)\n",
    "        try:\n",
    "            # Extract lists of arrays for y_true, p_calib, and tau_star\n",
    "            y_true_folds = df_base[df_base['model_name'] == base_to_use]['y_pred_binary'].iloc[0]\n",
    "            p_calib_folds = model_row['y_prob']\n",
    "            tau_star = model_row['threshold']\n",
    "\n",
    "            # Flatten the lists of arrays into single 1D vectors\n",
    "            y_true_flat = np.concatenate(y_true_folds)\n",
    "            p_calib_flat = np.concatenate(p_calib_folds)\n",
    "            \n",
    "            # Ensure data is consistent\n",
    "            if len(y_true_flat) != len(p_calib_flat):\n",
    "                print(f\"  -> WARNING: Mismatched length for y_true and p_calib. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        except (IndexError, KeyError) as e:\n",
    "            print(f\"  -> WARNING: Could not find base model '{base_to_use}' or required data for '{model_name}'. Skipping. Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 6. Execute Bootstrap CI Calculation\n",
    "        bootstrap_results = bootstrap_metrics(y_true_flat, p_calib_flat, tau_star, B=BOOTSTRAP_REPS)\n",
    "        \n",
    "        # Store results in a structured format\n",
    "        for metric_name, values in bootstrap_results.items():\n",
    "            point_est, lower_ci, upper_ci = values\n",
    "            all_bootstrap_results.append({\n",
    "                'data_source': data_source,\n",
    "                'model_name': model_name,\n",
    "                'metric': metric_name,\n",
    "                'point_estimate': point_est,\n",
    "                'lower_95_ci': lower_ci,\n",
    "                'upper_95_ci': upper_ci\n",
    "            })\n",
    "        print(\"  -> Completed bootstrap CI calculation.\")\n",
    "\n",
    "        # 7. Execute Decision-Curve Analysis\n",
    "        generate_dca_plot(\n",
    "            y_true=y_true_flat,\n",
    "            p_calib=p_calib_flat,\n",
    "            tau_star=tau_star,\n",
    "            data_source_name=data_source,\n",
    "            model_name=model_name,\n",
    "            save_dir=DCA_FIGURES_DIR,\n",
    "            B=BOOTSTRAP_REPS\n",
    "        )\n",
    "\n",
    "\n",
    "# 8. Final Aggregation and Output\n",
    "# Convert the list of results into a final DataFrame\n",
    "final_results_df = pd.DataFrame(all_bootstrap_results)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "output_csv_path = 'metrics_ci.csv'\n",
    "final_results_df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\\nANALYSIS COMPLETE\\n{'='*80}\")\n",
    "print(f\"Successfully saved all bootstrap confidence intervals to: {output_csv_path}\")\n",
    "print(\"\\nFinal Results Preview:\")\n",
    "display(final_results_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STARTING CROSS-DATASET DCA COMPARISON\n",
      "================================================================================\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: ASA Rule ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_ASA_Rule.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: AutoGluon ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_AutoGluon.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: GBT ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_GBT.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: Hybrid (MLP + LSTM) ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_Hybrid_MLP_+_LSTM.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: KNN ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_KNN.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: LSTM ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_LSTM.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: Logistic Regression ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_Logistic_Regression.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: MLP ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_MLP.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: Random Forest ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_Random_Forest.png\n",
      "\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~ COMPARING DATA SOURCES FOR: SVM (Linear) ~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "  -> Saved comparison plot to: figures/dca/dca_datasource_comparison_SVM_Linear.png\n",
      "\n",
      "================================================================================\n",
      "CROSS-DATASET DCA COMPARISON COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: CROSS-DATASET DECISION-CURVE ANALYSIS COMPARISON\n",
    "#\n",
    "# This cell generates comparative DCA plots to assess the value of adding\n",
    "# more data. It creates one plot per model, showing the DCA curve for that\n",
    "# model on the 'preop', 'intraop', and 'combined' datasets.\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from decision_curve import calculate_net_benefit_for_thresholds # Import the newly public helper\n",
    "\n",
    "# --- CONFIGURATION (Added to make cell self-contained) ---\n",
    "ALL_DATA_SOURCES = [\"preop\", \"intraop\", \"combined\"]\n",
    "RESULTS_DIR = '/home/server/Projects/data/AKI/results/'\n",
    "DCA_FIGURES_DIR = 'figures/dca'\n",
    "MODEL_BASE_MAP = {\n",
    "    'LSTM': 'base_54k',\n",
    "    'Hybrid (MLP + LSTM)': 'base_54k'\n",
    "}\n",
    "DEFAULT_BASE = 'base'\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "print(f\"{'='*80}\\nSTARTING CROSS-DATASET DCA COMPARISON\\n{'='*80}\")\n",
    "\n",
    "# Find all unique model names across all datasets\n",
    "all_models = set()\n",
    "for data_source in ALL_DATA_SOURCES:\n",
    "    input_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test_calibrated.pkl\")\n",
    "    try:\n",
    "        df = pd.read_pickle(input_pkl)\n",
    "        # Filter out base models\n",
    "        models_in_source = df[~df['model_name'].str.contains('base', na=False)]['model_name'].unique()\n",
    "        all_models.update(models_in_source)\n",
    "    except FileNotFoundError:\n",
    "        continue\n",
    "\n",
    "# Outer Loop: Iterate through each unique model name\n",
    "for model_name in sorted(list(all_models)):\n",
    "    print(f\"\\n{'~'*25} COMPARING DATA SOURCES FOR: {model_name} {'~'*25}\")\n",
    "    \n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    fig, ax = plt.subplots(figsize=(8, 6), dpi=300)\n",
    "    \n",
    "    # --- Data Collection for the current model ---\n",
    "    has_data = False\n",
    "    \n",
    "    # Inner Loop: Iterate through data sources to find this model's predictions\n",
    "    for data_source in ALL_DATA_SOURCES:\n",
    "        input_pkl = os.path.join(RESULTS_DIR, f\"tabular_{data_source}_test_calibrated.pkl\")\n",
    "        try:\n",
    "            df_calibrated = pd.read_pickle(input_pkl)\n",
    "            model_row = df_calibrated[df_calibrated['model_name'] == model_name]\n",
    "\n",
    "            if model_row.empty:\n",
    "                continue # Model not in this data source\n",
    "\n",
    "            # Extract data for this source\n",
    "            df_base = df_calibrated[df_calibrated['model_name'].str.contains('base', na=False)].copy()\n",
    "            base_to_use = MODEL_BASE_MAP.get(model_name, DEFAULT_BASE)\n",
    "            \n",
    "            y_true_folds = df_base[df_base['model_name'] == base_to_use]['y_pred_binary'].iloc[0]\n",
    "            p_calib_folds = model_row['y_prob'].iloc[0]\n",
    "\n",
    "            y_true_flat = np.concatenate(y_true_folds)\n",
    "            p_calib_flat = np.concatenate(p_calib_folds)\n",
    "\n",
    "            # Calculate Net Benefit for this data source\n",
    "            pt_grid = np.arange(0.01, 0.305, 0.005)\n",
    "            nb_model = calculate_net_benefit_for_thresholds(y_true_flat, p_calib_flat, pt_grid)\n",
    "            \n",
    "            # Plot the curve for this data source\n",
    "            ax.plot(pt_grid * 100, nb_model, lw=2, label=f'{data_source.capitalize()} Data')\n",
    "            has_data = True\n",
    "\n",
    "        except (FileNotFoundError, IndexError, KeyError):\n",
    "            continue\n",
    "            \n",
    "    # --- Finalize and Save the Comparative Plot ---\n",
    "    if has_data:\n",
    "        # Add reference lines (calculated from a representative dataset, e.g., 'combined')\n",
    "        try:\n",
    "            combined_pkl = os.path.join(RESULTS_DIR, \"tabular_combined_test_calibrated.pkl\")\n",
    "            df_comb = pd.read_pickle(combined_pkl)\n",
    "            df_base_comb = df_comb[df_comb['model_name'].str.contains('base', na=False)].copy()\n",
    "            y_true_comb = np.concatenate(df_base_comb.iloc[0]['y_pred_binary'])\n",
    "            \n",
    "            prevalence = y_true_comb.mean()\n",
    "            nb_all = prevalence - (1 - prevalence) * (pt_grid / (1 - pt_grid))\n",
    "            \n",
    "            ax.plot(pt_grid * 100, nb_all, color='black', lw=1.5, ls='--', label='Treat-All Strategy')\n",
    "            ax.axhline(0, color='grey', lw=1.5, ls='-', label='Treat-None Strategy')\n",
    "        except (FileNotFoundError, IndexError):\n",
    "            print(\"  -> Could not add reference lines; 'combined' data not found.\")\n",
    "\n",
    "        ax.set_title(f'DCA: Impact of Data Source on {model_name}', fontsize=16)\n",
    "        ax.set_xlabel('Risk Threshold Probability (%)', fontsize=12)\n",
    "        ax.set_ylabel('Net Benefit', fontsize=12)\n",
    "        ax.set_xlim(1, 30)\n",
    "        ax.set_ylim(-0.05, 0.2)\n",
    "        ax.legend(loc='upper right', fontsize=10)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        safe_model_name = model_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\")\n",
    "        save_path = os.path.join(DCA_FIGURES_DIR, f'dca_datasource_comparison_{safe_model_name}.png')\n",
    "        fig.savefig(save_path)\n",
    "        plt.close(fig)\n",
    "        print(f\"  -> Saved comparison plot to: {save_path}\")\n",
    "    else:\n",
    "        plt.close(fig)\n",
    "        print(f\"  -> No data found for model '{model_name}'. Skipping plot.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\nCROSS-DATASET DCA COMPARISON COMPLETE\\n{'='*80}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}